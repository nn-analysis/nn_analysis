<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 6.6.0" />
    <title>nn_analysis API documentation</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2264%22%20height%3D%2264%22%20viewBox%3D%2244.5%202.5%2015%2015%22%3E%3Cpath%20d%3D%22M49.351%2021.041c-.233-.721-.546-2.408-.772-4.076-.042-.09-.067-.187-.046-.288-.166-1.347-.277-2.625-.241-3.351-1.378-1.008-2.271-2.586-2.271-4.362%200-.976.272-1.935.788-2.774.057-.094.122-.18.184-.268-.033-.167-.052-.339-.052-.516%200-1.477%201.202-2.679%202.679-2.679.791%200%201.496.352%201.987.9a6.3%206.3%200%200%201%201.001.029c.492-.564%201.207-.929%202.012-.929%201.477%200%202.679%201.202%202.679%202.679a2.65%202.65%200%200%201-.269%201.148c.383.747.595%201.572.595%202.41%200%202.311-1.507%204.29-3.635%205.107.037.699.147%202.27.423%203.294l.137.461c.156%202.136-4.612%205.166-5.199%203.215zm.127-4.919a4.78%204.78%200%200%200%20.775-.584c-.172-.115-.505-.254-.88-.378zm.331%202.302l.828-.502c-.202-.143-.576-.328-.984-.49zm.45%202.157l.701-.403c-.214-.115-.536-.249-.891-.376l.19.779zM49.13%204.141c0%20.152.123.276.276.276s.275-.124.275-.276-.123-.276-.276-.276-.275.124-.275.276zm.735-.389a1.15%201.15%200%200%201%20.314.783%201.16%201.16%200%200%201-1.162%201.162c-.457%200-.842-.27-1.032-.653-.026.117-.042.238-.042.362a1.68%201.68%200%200%200%201.679%201.679%201.68%201.68%200%200%200%201.679-1.679c0-.843-.626-1.535-1.436-1.654zm3.076%201.654a1.68%201.68%200%200%200%201.679%201.679%201.68%201.68%200%200%200%201.679-1.679c0-.037-.009-.072-.011-.109-.21.3-.541.508-.935.508a1.16%201.16%200%200%201-1.162-1.162%201.14%201.14%200%200%201%20.474-.912c-.015%200-.03-.005-.045-.005-.926.001-1.679.754-1.679%201.68zm1.861-1.265c0%20.152.123.276.276.276s.275-.124.275-.276-.123-.276-.276-.276-.275.124-.275.276zm1.823%204.823c0-.52-.103-1.035-.288-1.52-.466.394-1.06.64-1.717.64-1.144%200-2.116-.725-2.499-1.738-.383%201.012-1.355%201.738-2.499%201.738-.867%200-1.631-.421-2.121-1.062-.307.605-.478%201.267-.478%201.942%200%202.486%202.153%204.51%204.801%204.51s4.801-2.023%204.801-4.51zm-3.032%209.156l-.146-.492c-.276-1.02-.395-2.457-.444-3.268a6.11%206.11%200%200%201-1.18.115%206.01%206.01%200%200%201-2.536-.562l.006.175c.802.215%201.848.612%202.021%201.25.079.295-.021.601-.274.837l-.598.501c.667.304%201.243.698%201.311%201.179.02.144.022.507-.393.787l-.564.365c1.285.521%201.361.96%201.381%201.126.018.142.011.496-.427.746l-.854.489c.064-1.19%201.985-2.585%202.697-3.248zM49.34%209.925c0-.667%201-.667%201%200%200%20.653.818%201.205%201.787%201.205s1.787-.552%201.787-1.205c0-.667%201-.667%201%200%200%201.216-1.25%202.205-2.787%202.205s-2.787-.989-2.787-2.205zm-.887-7.633c-.093.077-.205.114-.317.114a.5.5%200%200%201-.318-.886L49.183.397a.5.5%200%200%201%20.703.068.5.5%200%200%201-.069.703zm7.661-.065c-.086%200-.173-.022-.253-.068l-1.523-.893c-.575-.337-.069-1.2.506-.863l1.523.892a.5.5%200%200%201%20.179.685c-.094.158-.261.247-.432.247z%22%20fill%3D%22%233bb300%22/%3E%3C/svg%3E"/>


<style type="text/css">/*! * Bootstrap Reboot v5.0.0-beta1 (https://getbootstrap.com/) * Copyright 2011-2020 The Bootstrap Authors * Copyright 2011-2020 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}[tabindex="-1"]:focus:not(:focus-visible){outline:0!important}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus{outline:dotted 1px;outline:-webkit-focus-ring-color auto 5px}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
<style type="text/css">/*! pygments syntax highlighting */pre{line-height:125%;}td.linenos pre{color:#000000; background-color:#f0f0f0; padding-left:5px; padding-right:5px;}span.linenos{color:#000000; background-color:#f0f0f0; padding-left:5px; padding-right:5px;}td.linenos pre.special{color:#000000; background-color:#ffffc0; padding-left:5px; padding-right:5px;}span.linenos.special{color:#000000; background-color:#ffffc0; padding-left:5px; padding-right:5px;}.pdoc .hll{background-color:#ffffcc}.pdoc{background:#f8f8f8;}.pdoc .c{color:#408080; font-style:italic}.pdoc .err{border:1px solid #FF0000}.pdoc .k{color:#008000; font-weight:bold}.pdoc .o{color:#666666}.pdoc .ch{color:#408080; font-style:italic}.pdoc .cm{color:#408080; font-style:italic}.pdoc .cp{color:#BC7A00}.pdoc .cpf{color:#408080; font-style:italic}.pdoc .c1{color:#408080; font-style:italic}.pdoc .cs{color:#408080; font-style:italic}.pdoc .gd{color:#A00000}.pdoc .ge{font-style:italic}.pdoc .gr{color:#FF0000}.pdoc .gh{color:#000080; font-weight:bold}.pdoc .gi{color:#00A000}.pdoc .go{color:#888888}.pdoc .gp{color:#000080; font-weight:bold}.pdoc .gs{font-weight:bold}.pdoc .gu{color:#800080; font-weight:bold}.pdoc .gt{color:#0044DD}.pdoc .kc{color:#008000; font-weight:bold}.pdoc .kd{color:#008000; font-weight:bold}.pdoc .kn{color:#008000; font-weight:bold}.pdoc .kp{color:#008000}.pdoc .kr{color:#008000; font-weight:bold}.pdoc .kt{color:#B00040}.pdoc .m{color:#666666}.pdoc .s{color:#BA2121}.pdoc .na{color:#7D9029}.pdoc .nb{color:#008000}.pdoc .nc{color:#0000FF; font-weight:bold}.pdoc .no{color:#880000}.pdoc .nd{color:#AA22FF}.pdoc .ni{color:#999999; font-weight:bold}.pdoc .ne{color:#D2413A; font-weight:bold}.pdoc .nf{color:#0000FF}.pdoc .nl{color:#A0A000}.pdoc .nn{color:#0000FF; font-weight:bold}.pdoc .nt{color:#008000; font-weight:bold}.pdoc .nv{color:#19177C}.pdoc .ow{color:#AA22FF; font-weight:bold}.pdoc .w{color:#bbbbbb}.pdoc .mb{color:#666666}.pdoc .mf{color:#666666}.pdoc .mh{color:#666666}.pdoc .mi{color:#666666}.pdoc .mo{color:#666666}.pdoc .sa{color:#BA2121}.pdoc .sb{color:#BA2121}.pdoc .sc{color:#BA2121}.pdoc .dl{color:#BA2121}.pdoc .sd{color:#BA2121; font-style:italic}.pdoc .s2{color:#BA2121}.pdoc .se{color:#BB6622; font-weight:bold}.pdoc .sh{color:#BA2121}.pdoc .si{color:#BB6688; font-weight:bold}.pdoc .sx{color:#008000}.pdoc .sr{color:#BB6688}.pdoc .s1{color:#BA2121}.pdoc .ss{color:#19177C}.pdoc .bp{color:#008000}.pdoc .fm{color:#0000FF}.pdoc .vc{color:#19177C}.pdoc .vg{color:#19177C}.pdoc .vi{color:#19177C}.pdoc .vm{color:#19177C}.pdoc .il{color:#666666}</style>
<style type="text/css">/*! pdoc */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f7f7f7;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}body{background-color:var(--pdoc-background);}html, body{width:100%;height:100%;}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main{padding:2rem 3vw;}.git-button{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}#navtoggle{display:none;}}#togglestate{display:none;}nav.pdoc{--pad:1.75rem;--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent }nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc li{display:block;margin:0;padding:.2rem 0 .2rem var(--indent);transition:all 100ms;}nav.pdoc > div > ul > li{padding-left:0;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}html, main{scroll-behavior:smooth;}.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3, .pdoc h4{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{background-color:var(--code);border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--code);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.pdoc details{--shift:-40px;text-align:right;margin-top:var(--shift);margin-bottom:calc(0px - var(--shift));clear:both;filter:opacity(1);}.pdoc details:not([open]){height:0;overflow:visible;}.pdoc details > summary{font-size:.75rem;cursor:pointer;color:var(--muted);border-width:0;padding:0 .7em;display:inline-block;display:inline list-item;user-select:none;}.pdoc details > summary:focus{outline:0;}.pdoc details > div{margin-top:calc(0px - var(--shift) / 2);text-align:left;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc > section:first-of-type > .docstring{margin-bottom:3rem;}.pdoc .docstring pre{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc .headerlink{position:absolute;width:0;margin-left:-1.5rem;line-height:1.4rem;font-size:1.5rem;font-weight:normal;transition:all 100ms ease-in-out;opacity:0;}.pdoc .attr > .headerlink{margin-left:-2.5rem;}.pdoc *:hover > .headerlink,.pdoc *:target > .attr > .headerlink{opacity:1;}.pdoc .attr{color:var(--text);margin:1rem 0 .5rem;padding:.4rem 5rem .4rem 1rem;background-color:var(--accent);}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{white-space:pre-wrap;}.pdoc .annotation{color:var(--annotation);}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}</style>
</head>
<body>        <nav class="pdoc">
            <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
            <input id="togglestate" type="checkbox">
            <div>
                        <a class="pdoc-button module-list-button" href="./">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                            &nbsp;
                            Module Index
                        </a>


                    <h2>Contents</h2>
                    <ul>
  <li><a href="#installing-and-configuring-nn_analysis">Installing and configuring nn_analysis</a></li>
  <li><a href="#getting-started">Getting started</a>
  <ul>
    <li><a href="#getting-the-activations">Getting the activations</a></li>
    <li><a href="#fitting-activations-to-a-tuning-function">Fitting activations to a tuning function</a></li>
    <li><a href="#plot-the-results">Plot the results</a></li>
  </ul></li>
  <li><a href="#adding-new-neural-networks-to-the-code-analysis-system">Adding new neural networks to the code analysis system</a>
  <ul>
    <li><a href="#pytorch-models">PyTorch models</a></li>
    <li><a href="#tensorflow-models">TensorFlow models</a></li>
  </ul></li>
  <li><a href="#implement-your-own-stimulus-generator">Implement your own stimulus generator</a></li>
</ul>


                    <h2>Submodules</h2>
                    <ul>
                            <li><a href="nn_analysis/networks.html">nn_analysis.networks</a></li>
                            <li><a href="nn_analysis/statistics_helper.html">nn_analysis.statistics_helper</a></li>
                            <li><a href="nn_analysis/stimulus_generator.html">nn_analysis.stimulus_generator</a></li>
                            <li><a href="nn_analysis/storage.html">nn_analysis.storage</a></li>
                    </ul>

                    <h2>API Documentation</h2>
                        <ul class="memberlist">
            <li>
                    <a class="class" href="#Network">Network</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Network.__init__">Network</a>
                        </li>
                        <li>
                                <a class="variable" href="#Network.current_batch">current_batch</a>
                        </li>
                        <li>
                                <a class="function" href="#Network.run">run</a>
                        </li>
                        <li>
                                <a class="function" href="#Network.is_tf_one">is_tf_one</a>
                        </li>
                        <li>
                                <a class="function" href="#Network.extract_numpy_array">extract_numpy_array</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#FittingManager">FittingManager</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#FittingManager.__init__">FittingManager</a>
                        </li>
                        <li>
                                <a class="function" href="#FittingManager.calculate_best_fits">calculate_best_fits</a>
                        </li>
                        <li>
                                <a class="function" href="#FittingManager.fit_response_function_on_table_set">fit_response_function_on_table_set</a>
                        </li>
                        <li>
                                <a class="function" href="#FittingManager.fit_response_function">fit_response_function</a>
                        </li>
                        <li>
                                <a class="function" href="#FittingManager.generate_fake_responses">generate_fake_responses</a>
                        </li>
                        <li>
                                <a class="function" href="#FittingManager.test_response_fitting">test_response_fitting</a>
                        </li>
                        <li>
                                <a class="function" href="#FittingManager.linearise_sigma">linearise_sigma</a>
                        </li>
                        <li>
                                <a class="function" href="#FittingManager.init_parameter_set">init_parameter_set</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#StimulusGenerator">StimulusGenerator</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#StimulusGenerator.__init__">StimulusGenerator</a>
                        </li>
                        <li>
                                <a class="function" href="#StimulusGenerator.generate">generate</a>
                        </li>
                        <li>
                                <a class="variable" href="#StimulusGenerator.stimulus_description">stimulus_description</a>
                        </li>
                        <li>
                                <a class="variable" href="#StimulusGenerator.stim_x">stim_x</a>
                        </li>
                        <li>
                                <a class="variable" href="#StimulusGenerator.stim_y">stim_y</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#InputManager">InputManager</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#InputManager.__init__">InputManager</a>
                        </li>
                        <li>
                                <a class="function" href="#InputManager.valid">valid</a>
                        </li>
                        <li>
                                <a class="function" href="#InputManager.get">get</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#OutputManager">OutputManager</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#OutputManager.__init__">OutputManager</a>
                        </li>
                        <li>
                                <a class="function" href="#OutputManager.run">run</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#Plot">Plot</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Plot.__init__">Plot</a>
                        </li>
                        <li>
                                <a class="variable" href="#Plot.save_fig">save_fig</a>
                        </li>
                        <li>
                                <a class="variable" href="#Plot.save_fig_folder">save_fig_folder</a>
                        </li>
                        <li>
                                <a class="variable" href="#Plot.filetype">filetype</a>
                        </li>
                        <li>
                                <a class="variable" href="#Plot.title">title</a>
                        </li>
                        <li>
                                <a class="function" href="#Plot.show">show</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="function" href="#tf">tf</a>
            </li>
    </ul>


                    <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev">
                        built with <span class="visually-hidden">pdoc</span><img
                            alt="pdoc logo"
                            src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
                    </a>
            </div>
        </nav>
    <main class="pdoc">
            <section>
                    <h1 class="modulename">
nn_analysis    </h1>

                        <div class="docstring"><p>Analyse neural networks for feature tuning.</p>

<h2 id="installing-and-configuring-nn_analysis">Installing and configuring nn_analysis</h2>

<p>Install nn_analysis using the following <code>pip</code> command. This requires python &gt; 3.6.</p>

<pre><code>$ pip install nn_analysis
</code></pre>

<p>If you wish to use the plotting functions in any of the classes, you need to install Matplotlib. To do so you can use the following command:</p>

<pre><code>$ pip install matplotlib
</code></pre>

<p>Depending on the type of neural network you want to analyse you will need to install PyTorch or TensorFlow.
The required packages per network are listed in the table below.
When importing the network class, if the required pacakages are not installed, the error should also let you know what packages it expects.</p>

<table>
<thead>
<tr>
  <th>Network</th>
  <th>Package</th>
  <th>Version</th>
</tr>
</thead>
<tbody>
<tr>
  <td>AlexNet</td>
  <td>pytorch<br>pytorchvision</td>
  <td>latest</td>
</tr>
<tr>
  <td>PredNet</td>
  <td>tensorflow<br>python</td>
  <td>&lt; 2<br>3.6.*</td>
</tr>
</tbody>
</table>

<p>To install PyTorch use the following <code>pip</code> command:</p>

<pre><code>$ pip install pytorch
</code></pre>

<p>To install tensorflow use the following <code>pip</code> command:</p>

<pre><code>$ pip install tensorflow
</code></pre>

<p>The PredNet specific environment can also be installed by using the prednet variant of the package in <code>pip</code> using the following <code>pip</code> command.</p>

<pre><code>$ pip install nn_analysis-prednet
</code></pre>

<h2 id="getting-started">Getting started</h2>

<p>To get started first import the package and the inputs and networks you want to use.</p>

<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">nn_analysis</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn"><a href="nn_analysis/networks/prednet.html">nn_analysis.networks.prednet</a></span> <span class="kn">import</span> <span class="n">Prednet</span>
</code></pre></div>

<p>Define a table and a database to store the results in and initialise the storage manager.</p>

<div class="codehilite"><pre><span></span><code><span class="n">table</span> <span class="o">=</span> <span class="s1">&#39;activations_table&#39;</span>
<span class="n">database</span> <span class="o">=</span> <span class="n">Database</span><span class="p">(</span><span class="s2">&quot;/path/to/database/folder/&quot;</span><span class="p">)</span>
<span class="n">storage_manager</span> <span class="o">=</span> <span class="n">StorageManager</span><span class="p">(</span><span class="n">database</span><span class="p">)</span>
</code></pre></div>

<h3 id="getting-the-activations">Getting the activations</h3>

<p>Now we need to set up an input manager. The input will provide stimuli for the network using the input generator. In order to make a new input generator please see (link to that part of the documentation).
Here we will use the example of the build in <code>PRFInputManager</code>.</p>

<p>The input manager requires an input shape. This is the shape of the first layer in the network you want to use.
It is also possible to set a verbose flag for the input generator. By default, this flag is False.</p>

<div class="codehilite"><pre><span></span><code><span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">160</span><span class="p">)</span>
<span class="n">prf_stimulus_generator</span> <span class="o">=</span> <span class="n">PRFStimulusGenerator</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;prf_input&#39;</span><span class="p">,</span> <span class="n">storage_manager</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
<span class="n">prf_input_manager</span> <span class="o">=</span> <span class="n">InputManager</span><span class="p">(</span><span class="n">TableSet</span><span class="p">(</span><span class="s1">&#39;prf_input&#39;</span><span class="p">,</span> <span class="n">database</span><span class="p">),</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">prf_stimulus_generator</span><span class="p">)</span>
</code></pre></div>

<p>We then initialise the network. In this case I am using the prednet network as an example. The <code>json_file</code> and <code>weight_file</code> variables are strings with the location of those files.
The presentation variable determines the way stimuli are presented to the network. This way it is possible to get intermediates from the recurrent process rather than just the final result.
By default the network uses an iterative presentation and takes the mean from all the recorded iterative activations as an output.</p>

<div class="codehilite"><pre><span></span><code><span class="n">network</span> <span class="o">=</span> <span class="n">Prednet</span><span class="p">(</span><span class="n">json_file</span><span class="p">,</span> <span class="n">weights_file</span><span class="p">,</span> <span class="n">presentation</span><span class="o">=</span><span class="s1">&#39;iterative&#39;</span><span class="p">)</span>
</code></pre></div>

<p>We then define an output manager using the network, storage manager, and the input manager.</p>

<div class="codehilite"><pre><span></span><code><span class="n">output_manager</span> <span class="o">=</span> <span class="n">OutputManager</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">storage_manager</span><span class="p">,</span> <span class="n">prf_nd_input_manager</span><span class="p">)</span>
</code></pre></div>

<p>Now we can present the stimuli to the network batch wise. This step can take some time.
The resume parameter makes the network resume in case the program is halted intermediately.</p>

<div class="codehilite"><pre><span></span><code><span class="n">output_manager</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">resume</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<h3 id="fitting-activations-to-a-tuning-function">Fitting activations to a tuning function</h3>

<p>First open the table containing the activations by using the storage manager.</p>

<div class="codehilite"><pre><span></span><code><span class="n">responses_table_set</span> <span class="o">=</span> <span class="n">storage_manager</span><span class="o">.</span><span class="n">open_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</code></pre></div>

<p>Next initialise the fitting manager</p>

<div class="codehilite"><pre><span></span><code><span class="n">fitting_manager</span> <span class="o">=</span> <span class="n">FittingManager</span><span class="p">(</span><span class="n">storage_manager</span><span class="p">)</span>
</code></pre></div>

<p>Now we need some variables that are required for the fitting manager to work.</p>

<p>The <code>stim_x</code>, <code>stim_y</code>, and <code>stimulus</code> variables are used in the fitting procedure to generate a prediction from the function parameters it is testing. <code>stim_x</code> and <code>stim_y</code> both contain the feature representation of the thing you were trying to present.
So in the case of position data <code>stim_x</code> and <code>stim_y</code> are of size 128*160 and represent every point in the input image for image position data.
If the data you are testing is one dimensional, you can initialise the <code>stim_y</code> to a list of zeros of the same size as <code>stim_x</code>.
The <code>stimulus</code> variable represents which features we stimulated in each stimulus.
So the size of the <code>stimulus</code> variable is always the amount of stimuli that were presented x the size of <code>stim_x</code></p>

<div class="codehilite"><pre><span></span><code><span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span> <span class="o">=</span> <span class="n">fitting_manager</span><span class="o">.</span><span class="n">get_identity_stim_variables</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span>
<span class="n">stimulus</span> <span class="o">=</span> <span class="n">prf_stimulus_generator</span><span class="o">.</span><span class="n">get_stimulus</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>

<p>Next we need to initialise the parameter set. This is the set of parameters that will be tested by the fitting manager.
To do this it is possible to use the <code>init_parameter_set</code> function from the <code><a href="#FittingManager">FittingManager</a></code>.
This function requires a step size for each function parameter (x, y, and sigma) as well as the maximum value for each of those.
Finally, the function has an optional parameter for if the sigma should be linearised. This is useful when you want to use a logarithmic tuning function.
In this case we don't, so we left it False.</p>

<div class="codehilite"><pre><span></span><code><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">160</span><span class="p">)</span>
<span class="n">candidate_function_parameters</span> <span class="o">=</span> <span class="n">FittingManager</span><span class="o">.</span><span class="n">init_parameter_set</span><span class="p">((</span><span class="n">x_step</span><span class="p">,</span> <span class="n">y_step</span><span class="p">,</span> <span class="n">sigma_step</span><span class="p">),</span> <span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">max_sigma</span><span class="p">),</span>
                                                                  <span class="n">linearise_s</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<p>Next, we need to pick a table name to store the results in.</p>

<div class="codehilite"><pre><span></span><code><span class="n">fitting_results_table</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">table</span><span class="si">}</span><span class="s2">_fitting_results&quot;</span>
</code></pre></div>

<p>Finally, we can run the actual fitting procedure. By default, this function splits the calculation of the results into separate parts to not overload the memory or CPU.
The resulting <code>TableSet</code> is returned by the function.</p>

<p>By default, this function uses a gaussian tuning function. To use a different tuning function you can provide the <code>prediction_function</code> parameter.
This parameter is a string that is evaluated in the function. In this code you have the <code>stim_x</code> and <code>stim_y</code> variable as well as the <code>x</code>, <code>y</code>, and <code>sigma</code> for the function from the function parameter set.</p>

<div class="codehilite"><pre><span></span><code><span class="n">results_tbl_set</span> <span class="o">=</span> <span class="n">fitting_manager</span><span class="o">.</span><span class="n">fit_response_function_on_table_set</span><span class="p">(</span><span class="n">responses_table_set</span><span class="p">,</span> <span class="n">fitting_results_table</span><span class="p">,</span>
                                                                     <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">candidate_function_parameters</span><span class="p">,</span>
                                                                     <span class="n">stimulus</span><span class="o">=</span><span class="n">stimulus</span><span class="p">,</span>
                                                                     <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                     <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float16&#39;</span><span class="p">))</span>
</code></pre></div>

<p>Since the <code>results_tbl_set</code> contains all results, we need to still calculate which function had the best fit for each node in the network.
For this the <code><a href="#FittingManager">FittingManager</a></code> has a <code>calculate_best_fits</code> function that takes the <code>candidate_function_parameters</code> and the <code>results_tbl_set</code> and stores the best fits in a new table.</p>

<div class="codehilite"><pre><span></span><code><span class="n">best_fit_results_tbl</span> <span class="o">=</span> <span class="n">fitting_manager</span><span class="o">.</span><span class="n">calculate_best_fits</span><span class="p">(</span><span class="n">results_tbl_set</span><span class="p">,</span> <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">table</span><span class="o">+</span><span class="s1">&#39;_best&#39;</span><span class="p">)</span>
</code></pre></div>

<h3 id="plot-the-results">Plot the results</h3>

<p>You can choose many types of plots depending on the need in your project.
Here we give an example of a plot that might be more commonly useful as well as an explanation of how to access the relevant data for your plots.</p>

<p>Before we start plotting, it is good to understand how the results from the previous step look.
The best fits <code>TableSet</code> in the final step of the fitting procedure contains four rows.
The rows contain the goodness of fit, preferred x position, preferred y position, and the preferred σ respectively.
So, in order to retrieve the data for our plot we have to select the row with the type of data we want, and the column with the nodes in the network.</p>

<p>Getting the part of the network that you want to look at is easy thanks to the <code>get_subtable</code> function in the <code>TableSet</code> class.
In order to select just the first layer in a network all you need to do is <code>tableset.get_subtable(0)</code>.
The returned value is a <code>Table</code> or <code>TableSet</code> that both support slicing in the same way, so that any subsequent functions can be called unaltered.
For documentation about slicing in the <code>Table</code> or <code>TableSet</code> please see the documentation for those classes.</p>

<p>Now you are probably wondering: How does this look in practice?
Below is a bit of code that plots, for each layer, the field of vision (σ in the case of positional data).</p>

<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">LinearSegmentedColormap</span>

<span class="k">for</span> <span class="n">layer_subtable</span> <span class="ow">in</span> <span class="n">best_fit_results_tbl</span><span class="o">.</span><span class="n">subtables</span><span class="p">:</span>
    <span class="n">goodness_of_fits</span><span class="p">,</span> <span class="n">pref_x</span><span class="p">,</span> <span class="n">pref_y</span><span class="p">,</span> <span class="n">pref_s</span> <span class="o">=</span> <span class="n">best_fit_results_tbl</span><span class="o">.</span><span class="n">get_subtable</span><span class="p">(</span><span class="n">layer_subtable</span><span class="p">)[:]</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;scatter_density&#39;</span><span class="p">)</span>
    <span class="n">white_viridis</span> <span class="o">=</span> <span class="n">LinearSegmentedColormap</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="s1">&#39;white_viridis&#39;</span><span class="p">,</span> <span class="p">[</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;#ffffff&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">1e-20</span><span class="p">,</span> <span class="s1">&#39;#440053&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;#404388&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="s1">&#39;#2a788e&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="s1">&#39;#21a784&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="s1">&#39;#78d151&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;#fde624&#39;</span><span class="p">),</span>
    <span class="p">],</span> <span class="n">N</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
    <span class="n">density</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter_density</span><span class="p">(</span><span class="n">pref_s</span><span class="p">,</span> <span class="n">goodness_of_fits</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">white_viridis</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">density</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Number of neurons per pixel&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Goodness of Fit&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Field of vision&#39;</span><span class="p">)</span>
    <span class="n">Plot</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</code></pre></div>

<p>As you can see, we go through all the subtables in the main <code>TableSet</code>. In PredNet these correspond to the layers.
We then get the best fits for that layer using the <code>get_subtable</code> function.
Finally, we plot the GoF against the σ value using a matplotlib scatter plot.</p>

<h2 id="adding-new-neural-networks-to-the-code-analysis-system">Adding new neural networks to the code analysis system</h2>

<p>In order to extend the code analysis system to new neural networks a new class has to be created for that network in the networks sub package. This class has to extend the network class from that same sub package.</p>

<p>The new class has to implement a run function. The run function should run a batch of inputs, given in the input variable, through the model, record activations, and return those activations in the form of a nested tuple of np arrays along with a names dictionary that gives names to each of the items in the nested tuple.</p>

<p>Variables specific to the network can be added to the initialisation function of the class.</p>

<p>In practice, for most hierarchical networks, this all means setting up a model in the <code>__init__</code> function and running the input through that model in the <code>run</code> function. For pre-trained hierarchical PyTorch and TensorFlow/Keras models this means that it is possible to use a fairly standardised approach to building a new network class since recording activations has standardised functions.</p>

<h3 id="pytorch-models">PyTorch models</h3>

<p>For PyTorch models it is possible to load the model using the functions in the submodules in <code>torchvision.models</code> and then registering hooks for the layers in that model using the following function. This function also fills a labels variable that you can use as a names variable when returning output in the <code>run</code> function. Run this function after setting up the model in the <code>__init__</code> function. For an example of this method in use please see the AlexNet class.</p>

<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">__register_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function that registers hooks to save results from the network model in the run function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">hook_wrapper</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">__</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__raw_output</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">hook</span>
    <span class="k">for</span> <span class="n">submodel_name</span><span class="p">,</span> <span class="n">submodel</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">submodel</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">AlexNetModel</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">submodel</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">submodel_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">submodel_name</span>
            <span class="n">submodel</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="n">hook_wrapper</span><span class="p">(</span><span class="n">submodel_name</span><span class="p">))</span>
</code></pre></div>

<p>Note that this does not work well for recurrent models. There you would need to build your own implementation specific to that network.</p>

<h3 id="tensorflow-models">TensorFlow models</h3>

<p>For TensorFlow you will need a slightly different function but with much of the same idea. In the case of TensorFlow, the way to do this generally is to create a second model with the weights of the previous network. This new model has layers that are enclosed in a new type of layer that is accessible by hooks in a similar way to PyTorch models. The enclosed layer is shown below.</p>

<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span>

<span class="k">class</span> <span class="nc">LayerWithHooks</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
      <span class="bp">self</span><span class="p">,</span>
      <span class="n">layer</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">,</span>
      <span class="n">hooks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_layer</span> <span class="o">=</span> <span class="n">layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_hooks</span> <span class="o">=</span> <span class="n">hooks</span> <span class="ow">or</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hooks</span><span class="p">:</span>
      <span class="n">hook_result</span> <span class="o">=</span> <span class="n">hook</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">hook_result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">hook_result</span>
    <span class="k">return</span> <span class="n">output</span>

  <span class="k">def</span> <span class="nf">register_hook</span><span class="p">(</span>
      <span class="bp">self</span><span class="p">,</span>
      <span class="n">hook</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_hooks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hook</span><span class="p">)</span>
</code></pre></div>

<p>The method that registers those hooks is slightly more difficult than the one from PyTorch. An example of a method registering hooks is shown in the code below. In contrast to the default way of doing this in PyTorch, TensorFlow cannot automatically register hooks to each layer. Rather, this code has to be altered based on the network to add each layer in that network to the second model. The second model is the model that should eventually be called in the <code>run</code> function.</p>

<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">__register_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function that registers hooks to save results from the network model in the run function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__raw_output</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">def</span> <span class="nf">hook_wrapper</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__raw_output</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">hook</span>

    <span class="c1"># This second model should have the same layers and structure that the original model in self.model has.</span>
    <span class="c1"># For each layer you take a copy of the original layer that you add to the new model wrapped in a LayerWithHooks layer.</span>
    <span class="c1"># The layer with hooks should have the hook_wrapper that we defined above.</span>
    <span class="c1"># The run function should use the self.model2 model to run the network.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LayerWithHooks</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()),</span> <span class="p">[</span><span class="n">hook_wrapper</span><span class="p">(</span><span class="s1">&#39;First dense layer&#39;</span><span class="p">)]))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;tanh&#39;</span><span class="p">))</span>
</code></pre></div>

<h2 id="implement-your-own-stimulus-generator">Implement your own stimulus generator</h2>

<p>When running your own experiments, you will likely want to design a stimulus set tailored to that experiment.
To do so, you have to implement the <code><a href="#StimulusGenerator">StimulusGenerator</a></code> class.</p>

<p>The <code><a href="#StimulusGenerator">StimulusGenerator</a></code> has one function and three properties you have to implement: <code>generate()</code>, <code>stimulus_description</code>, <code>stim_x</code>, and <code>stim_y</code>.
<code>generate()</code> has one parameter <code>shape</code>. This parameter is the shape of the eventual complete output.
Any other variables you might want to use in your stimulus have to be in the <code>__init__()</code> method.
<code>generate()</code> does not return the output but only saves the stimuli in a <code>Table</code>/<code>TableSet</code>.
How you implement the generation of the stimuli is entirely up to you.</p>

<p>The variables <code>stimulus_description</code>, <code>stim_x</code>, and <code>stim_y</code> describe the stimuli in terms of the features in those stimuli and are used in the FittingManager.
<code>stimulus_description</code> is a matrix with, for each generated stimulus, a vector containing the features that were activated.
These vectors are of the same length as <code>stim_x</code> and <code>stim_y</code> and the values in the vector correspond to the location in these variables.
The <code>stim_x</code> and <code>stim_y</code> contain all possible combinations of feature x and feature y in the stimulus.</p>

<p>An example of a <code>stimulus_description</code>, <code>stim_x</code>, and <code>stim_y</code> in the case of 3 by 3 image positions where each position was stimulated once and one at a time would be:</p>

<div class="codehilite"><pre><span></span><code><span class="n">stimulus_description</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">stim_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">stim_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
</code></pre></div>

<p>For two-dimensional stimuli you can choose to implement the class <code>TwoDStimulusGenerator</code>.
This class has a pre-build function that automatically fills any other dimensions that a network might have such as, in the case of PredNet, a time dimension.
In order to implement it you have to implement the <code>_get_2d()</code> function. This function has two parameters: a two-dimensional shape, and an index.
You can use the two-dimensional shape to determine the shape of the output and the index to determine what to output at this point.
You still have to implement the <code>generate()</code> function from the <code><a href="#StimulusGenerator">StimulusGenerator</a></code> class.
In your implementation of this function you can use the <code>_generate_row()</code> function from the <code>TwoDStimulusGenerator</code> with you own indexing system.
For an example of how to do this you can look at the <code>PRFStimulusGenerator</code>.</p>

<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates all input and saves the input to a table</span>

<span class="sd">    Args:</span>
<span class="sd">        shape: (tuple) The expected shape of the input</span>

<span class="sd">    Returns:</span>
<span class="sd">        `Table` or `TableSet` containing the stimuli</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tbl</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">size_x</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">size_y</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_x</span> <span class="o">+</span> <span class="n">size_y</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__stride</span><span class="p">),</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">__verbose</span><span class="p">)):</span>
        <span class="n">tbl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_generate_row</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">i</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="o">...</span><span class="p">],),</span>
                                                           <span class="bp">self</span><span class="o">.</span><span class="n">__table</span><span class="p">,</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__table</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__table</span><span class="p">},</span>
                                                           <span class="n">append_rows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tbl</span>
</code></pre></div>
</div>

                        <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">[comment]: &lt;&gt;  (- Something about what this package is)</span>
<span class="sd">[comment]: &lt;&gt;  (- Something about the license)</span>
<span class="sd">[comment]: &lt;&gt;  (- Some links to the GitHub page, and the PyPi page)</span>
<span class="sd">Analyse neural networks for feature tuning.</span>

<span class="sd">## Installing and configuring nn_analysis</span>
<span class="sd">Install nn_analysis using the following `pip` command. This requires python &gt; 3.6.</span>

<span class="sd">    $ pip install nn_analysis</span>

<span class="sd">If you wish to use the plotting functions in any of the classes, you need to install Matplotlib. To do so you can use the following command:</span>

<span class="sd">    $ pip install matplotlib</span>

<span class="sd">Depending on the type of neural network you want to analyse you will need to install PyTorch or TensorFlow.</span>
<span class="sd">The required packages per network are listed in the table below.</span>
<span class="sd">When importing the network class, if the required pacakages are not installed, the error should also let you know what packages it expects.</span>

<span class="sd">|Network|Package|Version|</span>
<span class="sd">|---|---|---|</span>
<span class="sd">|AlexNet|pytorch&lt;br&gt;pytorchvision|latest|</span>
<span class="sd">|PredNet|tensorflow&lt;br&gt;python|&lt; 2&lt;br&gt;3.6.*|</span>

<span class="sd">To install PyTorch use the following `pip` command:</span>

<span class="sd">    $ pip install pytorch</span>

<span class="sd">To install tensorflow use the following `pip` command:</span>

<span class="sd">    $ pip install tensorflow</span>

<span class="sd">The PredNet specific environment can also be installed by using the prednet variant of the package in `pip` using the following `pip` command.</span>

<span class="sd">    $ pip install nn_analysis-prednet</span>

<span class="sd">## Getting started</span>
<span class="sd">To get started first import the package and the inputs and networks you want to use.</span>

<span class="sd">```python</span>
<span class="sd">from nn_analysis import *</span>
<span class="sd">from nn_analysis.networks.prednet import Prednet</span>
<span class="sd">```</span>

<span class="sd">Define a table and a database to store the results in and initialise the storage manager.</span>

<span class="sd">```python</span>
<span class="sd">table = &#39;activations_table&#39;</span>
<span class="sd">database = Database(&quot;/path/to/database/folder/&quot;)</span>
<span class="sd">storage_manager = StorageManager(database)</span>
<span class="sd">```</span>

<span class="sd">### Getting the activations</span>
<span class="sd">Now we need to set up an input manager. The input will provide stimuli for the network using the input generator. In order to make a new input generator please see (link to that part of the documentation).</span>
<span class="sd">Here we will use the example of the build in `PRFInputManager`.</span>

<span class="sd">The input manager requires an input shape. This is the shape of the first layer in the network you want to use.</span>
<span class="sd">It is also possible to set a verbose flag for the input generator. By default, this flag is False.</span>

<span class="sd">```python</span>
<span class="sd">verbose = True</span>
<span class="sd">input_shape = (1,3,128,160)</span>
<span class="sd">prf_stimulus_generator = PRFStimulusGenerator(1, &#39;prf_input&#39;, storage_manager, verbose=verbose)</span>
<span class="sd">prf_input_manager = InputManager(TableSet(&#39;prf_input&#39;, database), input_shape, prf_stimulus_generator)</span>
<span class="sd">```</span>

<span class="sd">We then initialise the network. In this case I am using the prednet network as an example. The `json_file` and `weight_file` variables are strings with the location of those files.</span>
<span class="sd">The presentation variable determines the way stimuli are presented to the network. This way it is possible to get intermediates from the recurrent process rather than just the final result.</span>
<span class="sd">By default the network uses an iterative presentation and takes the mean from all the recorded iterative activations as an output.</span>

<span class="sd">```python</span>
<span class="sd">network = Prednet(json_file, weights_file, presentation=&#39;iterative&#39;)</span>
<span class="sd">```</span>

<span class="sd">We then define an output manager using the network, storage manager, and the input manager.</span>

<span class="sd">```python</span>
<span class="sd">output_manager = OutputManager(network, storage_manager, prf_nd_input_manager)</span>
<span class="sd">```</span>

<span class="sd">Now we can present the stimuli to the network batch wise. This step can take some time.</span>
<span class="sd">The resume parameter makes the network resume in case the program is halted intermediately.</span>

<span class="sd">```python</span>
<span class="sd">output_manager.run(table, batch_size=20, resume=True, verbose=True)</span>
<span class="sd">```</span>

<span class="sd">### Fitting activations to a tuning function</span>
<span class="sd">First open the table containing the activations by using the storage manager.</span>

<span class="sd">```python</span>
<span class="sd">responses_table_set = storage_manager.open_table(table)</span>
<span class="sd">```</span>

<span class="sd">Next initialise the fitting manager</span>

<span class="sd">```python</span>
<span class="sd">fitting_manager = FittingManager(storage_manager)</span>
<span class="sd">```</span>

<span class="sd">Now we need some variables that are required for the fitting manager to work.</span>

<span class="sd">The `stim_x`, `stim_y`, and `stimulus` variables are used in the fitting procedure to generate a prediction from the function parameters it is testing. `stim_x` and `stim_y` both contain the feature representation of the thing you were trying to present.</span>
<span class="sd">So in the case of position data `stim_x` and `stim_y` are of size 128*160 and represent every point in the input image for image position data.</span>
<span class="sd">If the data you are testing is one dimensional, you can initialise the `stim_y` to a list of zeros of the same size as `stim_x`.</span>
<span class="sd">The `stimulus` variable represents which features we stimulated in each stimulus.</span>
<span class="sd">So the size of the `stimulus` variable is always the amount of stimuli that were presented x the size of `stim_x`</span>

<span class="sd">```python</span>
<span class="sd">stim_x, stim_y = fitting_manager.get_identity_stim_variables(*shape)</span>
<span class="sd">stimulus = prf_stimulus_generator.get_stimulus(shape)</span>
<span class="sd">```</span>

<span class="sd">Next we need to initialise the parameter set. This is the set of parameters that will be tested by the fitting manager.</span>
<span class="sd">To do this it is possible to use the `init_parameter_set` function from the `FittingManager`.</span>
<span class="sd">This function requires a step size for each function parameter (x, y, and sigma) as well as the maximum value for each of those.</span>
<span class="sd">Finally, the function has an optional parameter for if the sigma should be linearised. This is useful when you want to use a logarithmic tuning function.</span>
<span class="sd">In this case we don&#39;t, so we left it False.</span>

<span class="sd">```python</span>
<span class="sd">shape = (128, 160)</span>
<span class="sd">candidate_function_parameters = FittingManager.init_parameter_set((x_step, y_step, sigma_step), (*shape, max_sigma),</span>
<span class="sd">                                                                  linearise_s=False)</span>
<span class="sd">```</span>

<span class="sd">Next, we need to pick a table name to store the results in.</span>

<span class="sd">```python</span>
<span class="sd">fitting_results_table = f&quot;{table}_fitting_results&quot;</span>
<span class="sd">```</span>

<span class="sd">Finally, we can run the actual fitting procedure. By default, this function splits the calculation of the results into separate parts to not overload the memory or CPU.</span>
<span class="sd">The resulting `TableSet` is returned by the function.</span>

<span class="sd">By default, this function uses a gaussian tuning function. To use a different tuning function you can provide the `prediction_function` parameter.</span>
<span class="sd">This parameter is a string that is evaluated in the function. In this code you have the `stim_x` and `stim_y` variable as well as the `x`, `y`, and `sigma` for the function from the function parameter set.</span>

<span class="sd">```python</span>
<span class="sd">results_tbl_set = fitting_manager.fit_response_function_on_table_set(responses_table_set, fitting_results_table,</span>
<span class="sd">                                                                     stim_x, stim_y, candidate_function_parameters,</span>
<span class="sd">                                                                     stimulus=stimulus,</span>
<span class="sd">                                                                     verbose=True,</span>
<span class="sd">                                                                     dtype=np.dtype(&#39;float16&#39;))</span>
<span class="sd">```</span>

<span class="sd">Since the `results_tbl_set` contains all results, we need to still calculate which function had the best fit for each node in the network.</span>
<span class="sd">For this the `FittingManager` has a `calculate_best_fits` function that takes the `candidate_function_parameters` and the `results_tbl_set` and stores the best fits in a new table.</span>

<span class="sd">```python</span>
<span class="sd">best_fit_results_tbl = fitting_manager.calculate_best_fits(results_tbl_set, candidate_function_parameters, table+&#39;_best&#39;)</span>
<span class="sd">```</span>

<span class="sd">### Plot the results</span>
<span class="sd">You can choose many types of plots depending on the need in your project.</span>
<span class="sd">Here we give an example of a plot that might be more commonly useful as well as an explanation of how to access the relevant data for your plots.</span>

<span class="sd">Before we start plotting, it is good to understand how the results from the previous step look.</span>
<span class="sd">The best fits `TableSet` in the final step of the fitting procedure contains four rows.</span>
<span class="sd">The rows contain the goodness of fit, preferred x position, preferred y position, and the preferred σ respectively.</span>
<span class="sd">So, in order to retrieve the data for our plot we have to select the row with the type of data we want, and the column with the nodes in the network.</span>

<span class="sd">Getting the part of the network that you want to look at is easy thanks to the `get_subtable` function in the `TableSet` class.</span>
<span class="sd">In order to select just the first layer in a network all you need to do is `tableset.get_subtable(0)`.</span>
<span class="sd">The returned value is a `Table` or `TableSet` that both support slicing in the same way, so that any subsequent functions can be called unaltered.</span>
<span class="sd">For documentation about slicing in the `Table` or `TableSet` please see the documentation for those classes.</span>

<span class="sd">Now you are probably wondering: How does this look in practice?</span>
<span class="sd">Below is a bit of code that plots, for each layer, the field of vision (σ in the case of positional data).</span>

<span class="sd">```python</span>
<span class="sd">import matplotlib.pyplot as plt</span>
<span class="sd">from matplotlib.colors import LinearSegmentedColormap</span>

<span class="sd">for layer_subtable in best_fit_results_tbl.subtables:</span>
<span class="sd">    goodness_of_fits, pref_x, pref_y, pref_s = best_fit_results_tbl.get_subtable(layer_subtable)[:]</span>
<span class="sd">    fig = plt.figure()</span>
<span class="sd">    ax = fig.add_subplot(1, 1, 1, projection=&#39;scatter_density&#39;)</span>
<span class="sd">    white_viridis = LinearSegmentedColormap.from_list(&#39;white_viridis&#39;, [</span>
<span class="sd">        (0, &#39;#ffffff&#39;),</span>
<span class="sd">        (1e-20, &#39;#440053&#39;),</span>
<span class="sd">        (0.2, &#39;#404388&#39;),</span>
<span class="sd">        (0.4, &#39;#2a788e&#39;),</span>
<span class="sd">        (0.6, &#39;#21a784&#39;),</span>
<span class="sd">        (0.8, &#39;#78d151&#39;),</span>
<span class="sd">        (1, &#39;#fde624&#39;),</span>
<span class="sd">    ], N=256)</span>
<span class="sd">    density = ax.scatter_density(pref_s, goodness_of_fits, cmap=white_viridis)</span>
<span class="sd">    fig.colorbar(density, label=&#39;Number of neurons per pixel&#39;)</span>
<span class="sd">    ax.set_ylabel(&#39;Goodness of Fit&#39;)</span>
<span class="sd">    ax.set_xlabel(&#39;Field of vision&#39;)</span>
<span class="sd">    Plot.show(plt)</span>
<span class="sd">```</span>

<span class="sd">As you can see, we go through all the subtables in the main `TableSet`. In PredNet these correspond to the layers.</span>
<span class="sd">We then get the best fits for that layer using the `get_subtable` function.</span>
<span class="sd">Finally, we plot the GoF against the σ value using a matplotlib scatter plot.</span>

<span class="sd">## Adding new neural networks to the code analysis system</span>
<span class="sd">In order to extend the code analysis system to new neural networks a new class has to be created for that network in the networks sub package. This class has to extend the network class from that same sub package.</span>

<span class="sd">The new class has to implement a run function. The run function should run a batch of inputs, given in the input variable, through the model, record activations, and return those activations in the form of a nested tuple of np arrays along with a names dictionary that gives names to each of the items in the nested tuple.</span>

<span class="sd">Variables specific to the network can be added to the initialisation function of the class.</span>

<span class="sd">In practice, for most hierarchical networks, this all means setting up a model in the `__init__` function and running the input through that model in the `run` function. For pre-trained hierarchical PyTorch and TensorFlow/Keras models this means that it is possible to use a fairly standardised approach to building a new network class since recording activations has standardised functions.</span>

<span class="sd">### PyTorch models</span>
<span class="sd">For PyTorch models it is possible to load the model using the functions in the submodules in `torchvision.models` and then registering hooks for the layers in that model using the following function. This function also fills a labels variable that you can use as a names variable when returning output in the `run` function. Run this function after setting up the model in the `__init__` function. For an example of this method in use please see the AlexNet class.</span>

<span class="sd">```python</span>
<span class="sd">def __register_hooks(self):</span>
<span class="sd">    \&quot;\&quot;\&quot;</span>
<span class="sd">    Function that registers hooks to save results from the network model in the run function.</span>
<span class="sd">    \&quot;\&quot;\&quot;</span>
<span class="sd">    def hook_wrapper(name: str):</span>
<span class="sd">        def hook(_, __, output):</span>
<span class="sd">            self.__raw_output[name] = output.detach().numpy()</span>

<span class="sd">        return hook</span>
<span class="sd">    for submodel_name, submodel in self.model.named_modules():</span>
<span class="sd">        if type(submodel) is not AlexNetModel and type(submodel) is not nn.Sequential:</span>
<span class="sd">            self.labels[submodel_name] = submodel_name</span>
<span class="sd">            submodel.register_forward_hook(hook_wrapper(submodel_name))</span>
<span class="sd">```</span>


<span class="sd">Note that this does not work well for recurrent models. There you would need to build your own implementation specific to that network.</span>

<span class="sd">### TensorFlow models</span>
<span class="sd">For TensorFlow you will need a slightly different function but with much of the same idea. In the case of TensorFlow, the way to do this generally is to create a second model with the weights of the previous network. This new model has layers that are enclosed in a new type of layer that is accessible by hooks in a similar way to PyTorch models. The enclosed layer is shown below.</span>

<span class="sd">```python</span>
<span class="sd">import tensorflow as tf</span>
<span class="sd">from typing import List, Callable, Optional</span>

<span class="sd">class LayerWithHooks(tf.keras.layers.Layer):</span>
<span class="sd">  def __init__(</span>
<span class="sd">      self,</span>
<span class="sd">      layer: tf.keras.layers.Layer,</span>
<span class="sd">      hooks: List[Callable[[tf.Tensor, tf.Tensor], Optional[tf.Tensor]]] = None):</span>
<span class="sd">    super().__init__()</span>
<span class="sd">    self._layer = layer</span>
<span class="sd">    self._hooks = hooks or []</span>

<span class="sd">  def call(self, input: tf.Tensor) -&gt; tf.Tensor:</span>
<span class="sd">    output = self._layer(input)</span>
<span class="sd">    for hook in self._hooks:</span>
<span class="sd">      hook_result = hook(input, output)</span>
<span class="sd">      if hook_result is not None:</span>
<span class="sd">        output = hook_result</span>
<span class="sd">    return output</span>

<span class="sd">  def register_hook(</span>
<span class="sd">      self,</span>
<span class="sd">      hook: Callable[[tf.Tensor, tf.Tensor], Optional[tf.Tensor]]) -&gt; None:</span>
<span class="sd">    self._hooks.append(hook)</span>
<span class="sd">```</span>

<span class="sd">The method that registers those hooks is slightly more difficult than the one from PyTorch. An example of a method registering hooks is shown in the code below. In contrast to the default way of doing this in PyTorch, TensorFlow cannot automatically register hooks to each layer. Rather, this code has to be altered based on the network to add each layer in that network to the second model. The second model is the model that should eventually be called in the `run` function.</span>

<span class="sd">```python</span>
<span class="sd">def __register_hooks(self):</span>
<span class="sd">    \&quot;\&quot;\&quot;</span>
<span class="sd">    Function that registers hooks to save results from the network model in the run function.</span>
<span class="sd">    \&quot;\&quot;\&quot;</span>
<span class="sd">    self.__raw_output = {}</span>
<span class="sd">    def hook_wrapper(name: str):</span>
<span class="sd">        def hook(_, output):</span>
<span class="sd">            self.__raw_output[name] = tf.identity(output).numpy()</span>

<span class="sd">        return hook</span>

<span class="sd">    # This second model should have the same layers and structure that the original model in self.model has.</span>
<span class="sd">    # For each layer you take a copy of the original layer that you add to the new model wrapped in a LayerWithHooks layer.</span>
<span class="sd">    # The layer with hooks should have the hook_wrapper that we defined above.</span>
<span class="sd">    # The run function should use the self.model2 model to run the network.</span>
<span class="sd">    self.model2 = Sequential()</span>
<span class="sd">    self.model2.add(LayerWithHooks(Dense(20, 64, weights=model.layers[0].get_weights()), [hook_wrapper(&#39;First dense layer&#39;)]))</span>
<span class="sd">    self.model2.add(Activation(&#39;tanh&#39;))</span>
<span class="sd">```</span>

<span class="sd">## Implement your own stimulus generator</span>
<span class="sd">When running your own experiments, you will likely want to design a stimulus set tailored to that experiment.</span>
<span class="sd">To do so, you have to implement the `StimulusGenerator` class.</span>

<span class="sd">The `StimulusGenerator` has one function and three properties you have to implement: `generate()`, `stimulus_description`, `stim_x`, and `stim_y`.</span>
<span class="sd">`generate()` has one parameter `shape`. This parameter is the shape of the eventual complete output.</span>
<span class="sd">Any other variables you might want to use in your stimulus have to be in the `__init__()` method.</span>
<span class="sd">`generate()` does not return the output but only saves the stimuli in a `Table`/`TableSet`.</span>
<span class="sd">How you implement the generation of the stimuli is entirely up to you.</span>

<span class="sd">The variables `stimulus_description`, `stim_x`, and `stim_y` describe the stimuli in terms of the features in those stimuli and are used in the FittingManager.</span>
<span class="sd">`stimulus_description` is a matrix with, for each generated stimulus, a vector containing the features that were activated.</span>
<span class="sd">These vectors are of the same length as `stim_x` and `stim_y` and the values in the vector correspond to the location in these variables.</span>
<span class="sd">The `stim_x` and `stim_y` contain all possible combinations of feature x and feature y in the stimulus.</span>

<span class="sd">An example of a `stimulus_description`, `stim_x`, and `stim_y` in the case of 3 by 3 image positions where each position was stimulated once and one at a time would be:</span>

<span class="sd">```python</span>
<span class="sd">stimulus_description = np.array([[1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,1,0,0,0,0],[0,0,0,0,0,1,0,0,0],[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,1]])</span>
<span class="sd">stim_x = np.array([1,1,1,2,2,2,3,3,3])</span>
<span class="sd">stim_y = np.array([1,2,3,1,2,3,1,2,3])</span>
<span class="sd">```</span>

<span class="sd">For two-dimensional stimuli you can choose to implement the class `TwoDStimulusGenerator`.</span>
<span class="sd">This class has a pre-build function that automatically fills any other dimensions that a network might have such as, in the case of PredNet, a time dimension.</span>
<span class="sd">In order to implement it you have to implement the `_get_2d()` function. This function has two parameters: a two-dimensional shape, and an index.</span>
<span class="sd">You can use the two-dimensional shape to determine the shape of the output and the index to determine what to output at this point.</span>
<span class="sd">You still have to implement the `generate()` function from the `StimulusGenerator` class.</span>
<span class="sd">In your implementation of this function you can use the `_generate_row()` function from the `TwoDStimulusGenerator` with you own indexing system.</span>
<span class="sd">For an example of how to do this you can look at the `PRFStimulusGenerator`.</span>

<span class="sd">```python</span>
<span class="sd">def generate(self, shape: tuple) -&gt; Union[Table, TableSet]:</span>
<span class="sd">    \&quot;\&quot;\&quot;</span>
<span class="sd">    Generates all input and saves the input to a table</span>

<span class="sd">    Args:</span>
<span class="sd">        shape: (tuple) The expected shape of the input</span>

<span class="sd">    Returns:</span>
<span class="sd">        `Table` or `TableSet` containing the stimuli</span>
<span class="sd">    \&quot;\&quot;\&quot;</span>
<span class="sd">    tbl = None</span>
<span class="sd">    size_x = shape[-1]</span>
<span class="sd">    size_y = shape[-2]</span>
<span class="sd">    for i in tqdm(range(0, size_x + size_y + 2, self.__stride), leave=False, disable=(not self.__verbose)):</span>
<span class="sd">        tbl = self.__storage_manager.save_result_table_set((self._generate_row(shape, i)[np.newaxis, ...],),</span>
<span class="sd">                                                           self.__table, {self.__table: self.__table},</span>
<span class="sd">                                                           append_rows=True)</span>
<span class="sd">    return tbl</span>
<span class="sd">```</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">abc</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="n">tensorflow</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">tf</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="kc">None</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">compat</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="kc">None</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="kc">None</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span> <span class="o">=</span> <span class="n">Any</span>
    <span class="n">tensorflow</span> <span class="o">=</span> <span class="kc">False</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
    <span class="n">no_plotting</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">no_plotting</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">plt</span> <span class="o">=</span> <span class="kc">None</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="kn">from</span> <span class="nn">.storage</span> <span class="kn">import</span> <span class="o">*</span>


<span class="c1"># noinspection PyUnresolvedReferences</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract Network class</span>
<span class="sd">    Subclasses of this class will be the only actual interaction point between networks and the rest of the program.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        current_batch: (int) The current batch</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">current_batch</span><span class="p">:</span> <span class="nb">int</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_array</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the stimuli (in the `input_array`) through the network and returns the results.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; Network().run(np.array([[1,2,3,4], [2,3,4,5]]))</span>
<span class="sd">        (tuple of results split up in subparts for the subtable structure of the `TableSet`, dict of names for the structure of the `TableSet`.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_array: Input array containing all the stimuli in this batch</span>

<span class="sd">        Returns:</span>
<span class="sd">            The results as a tuple and the labels as a dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">is_tf_one</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Helper function for checking the TensorFlow function</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tensorflow</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&lt;=</span> <span class="s2">&quot;2&quot;</span>

    <span class="k">def</span> <span class="nf">extract_numpy_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">to_extract</span><span class="p">,</span> <span class="n">session</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        If the tensorflow version is version 1, the extraction of arrays from tensors follows a different algorithm.</span>
<span class="sd">        This function provides a universal function to perform the operation.</span>

<span class="sd">        The session is an optional variable that allows you to share the same session across different extractions</span>
<span class="sd">        saving memory.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; Network().extract_numpy_array([tf.Tensor(), tf.Tensor])</span>
<span class="sd">        [Array([]), Array([])]</span>
<span class="sd">        &gt;&gt;&gt; Network().extract_numpy_array({&#39;A&#39;: tf.Tensor(), &#39;B&#39;: tf.Tensor()})</span>
<span class="sd">        {&#39;A&#39;: Array([]), &#39;B&#39;: Array([])}</span>

<span class="sd">        Args:</span>
<span class="sd">            to_extract: The tensor or structure containing tensors that needs to be extracted. This structure can be of any type but may not contain any np.ndarrays.</span>
<span class="sd">            session (optional): The TensorFlow session.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The resulting np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tensorflow</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;tensorflow could not be imported&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tf_one</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">to_extract</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">to_extract</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">to_extract</span>
                <span class="n">tensor_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tensor_type</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">to_extract</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">(</span><span class="n">to_extract</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">session</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tensor_type</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)):</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">(</span><span class="n">to_extract</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">session</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tensor_type</span> <span class="ow">is</span> <span class="nb">tuple</span><span class="p">:</span>
                    <span class="c1"># Make a list, tuples cannot be changed</span>
                    <span class="n">new_output</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)):</span>
                        <span class="n">new_output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">(</span><span class="n">to_extract</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">session</span><span class="p">))</span>
                    <span class="k">return</span> <span class="n">new_output</span>
                <span class="k">return</span> <span class="n">output</span>
        <span class="k">if</span> <span class="n">session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
                <span class="k">return</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">FittingManager</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class responsible for fitting response functions to recorded activations and calculating the best fits.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        storage_manager: StorageManager used to store the results from fittings.</span>

<span class="sd">    Args:</span>
<span class="sd">        storage_manager: StorageManager used to store the results from fittings.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">storage_manager</span><span class="p">:</span> <span class="n">StorageManager</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span> <span class="o">=</span> <span class="n">storage_manager</span>

    <span class="k">def</span> <span class="nf">calculate_best_fits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">candidate_function_parameters</span><span class="p">,</span>
                            <span class="n">table</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Use already generated results in a Table, TableSet, or np.ndarray to get the best fits from those sets.</span>
<span class="sd">        Saves those best_fits to the table.</span>

<span class="sd">        It the results are a TableSet this function will preserve the organisation of the original TableSet.</span>

<span class="sd">        Args:</span>
<span class="sd">            results: `Table`, `TableSet`, np.ndarray with results.</span>
<span class="sd">            candidate_function_parameters: The set with candidate function parameters</span>
<span class="sd">            table: Table to save the best fits to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Array with the resulting best_fits. If a table name has been provided, a TableSet with the best fits.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">best_predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">results</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">))</span>
        <span class="n">results_ndarray</span> <span class="o">=</span> <span class="n">results</span><span class="p">[:]</span>
        <span class="n">best_r2s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmax</span><span class="p">(</span><span class="n">results_ndarray</span><span class="p">[:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">results_ndarray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">best_r2</span> <span class="o">=</span> <span class="n">best_r2s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">best_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">results_ndarray</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">best_r2</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">best_x</span><span class="p">,</span> <span class="n">best_y</span><span class="p">,</span> <span class="n">best_s</span> <span class="o">=</span> <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">best_index</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> \
                                     <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">best_index</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> \
                                     <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">best_index</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
            <span class="n">best_predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_r2</span><span class="p">,</span> <span class="n">best_x</span><span class="p">,</span> <span class="n">best_y</span><span class="p">,</span> <span class="n">best_s</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">table</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TableSet</span><span class="p">:</span>
                <span class="n">table_labels</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">recurrent_subtables</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__unpack_tuple_according_to_labels</span><span class="p">(</span><span class="n">best_predicted</span><span class="p">,</span> <span class="n">results</span><span class="p">),</span>
                                                                  <span class="n">table</span><span class="p">,</span> <span class="n">table_labels</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__save__</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">best_predicted</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">best_predicted</span>

    <span class="k">def</span> <span class="nf">__unpack_tuple_according_to_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">table_set</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Takes a TableSet and a result array to split the result array into parts fitting into the provided TableSet</span>

<span class="sd">        Args:</span>
<span class="sd">            result: np.ndarray containing items from a</span>
<span class="sd">            table_set: The TableSet the results will be formed to</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple of the results split to fit the TableSet&#39;s labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Keep track of the ncols so far to determine which part of the results needs to be selected</span>
        <span class="n">ncols_so_far</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Go through the tables and subtables recursively</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">table_set</span><span class="o">.</span><span class="n">subtables</span><span class="p">:</span>
            <span class="n">subtable</span> <span class="o">=</span> <span class="n">table_set</span><span class="o">.</span><span class="n">get_subtable</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            <span class="c1"># Select the results for this subpart</span>
            <span class="n">results_selection</span> <span class="o">=</span> <span class="n">result</span><span class="p">[:,</span> <span class="n">ncols_so_far</span><span class="p">:</span><span class="n">ncols_so_far</span><span class="o">+</span><span class="n">subtable</span><span class="o">.</span><span class="n">ncols</span><span class="p">]</span>
            <span class="c1"># Either recursively enter the subtableset or add the results selection directly</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">subtable</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TableSet</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__unpack_tuple_according_to_labels</span><span class="p">(</span><span class="n">results_selection</span><span class="p">,</span>
                                                                       <span class="n">subtable</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">results_selection</span><span class="p">)</span>
            <span class="c1"># Update the counters</span>
            <span class="n">ncols_so_far</span> <span class="o">+=</span> <span class="n">subtable</span><span class="o">.</span><span class="n">ncols</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Return the results as a tuple</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit_response_function_on_table_set</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">responses</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">,</span> <span class="n">table_set</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                                           <span class="n">candidate_function_parameters</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                                           <span class="n">prediction_function</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&quot;</span><span class="p">,</span>
                                           <span class="n">stimulus_description</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">parallel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                           <span class="n">dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">split_calculation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a new TableSet based on the input TableSet.</span>
<span class="sd">        Uses the fit response function to calculate the goodness of fit for all recorded nodes in the responses TableSet.</span>
<span class="sd">        This can be done in a, less computationally intensive, way by setting split_calculation to True.</span>
<span class="sd">        Then the program will go through the activations one subtable (not subtableset) of the responses TableSet at the time.</span>

<span class="sd">        Besides that the function has the necessary parameters for the `fit_response_function`.</span>
<span class="sd">        The `fit_response_function` is a function that uses a prediction function to generate predictions for the activations of neurons for all the</span>
<span class="sd">        candidate function parameters described in the `candidate_function_parameters` variable.</span>

<span class="sd">        By default, the prediction_function is a gaussian function. Another example of a prediction functions could be &#39;stim_x**x&#39;.</span>
<span class="sd">        At the point of executing the prediction function stim_x, stim_y, x, y, and s are the available parameters.</span>

<span class="sd">        The predictions are compared to the recorded responses to determine a goodness of fit.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        fit_response_function : The function this function uses. This function&#39;s documentation also contains some examples of input.</span>

<span class="sd">        Args:</span>
<span class="sd">            responses: Recorded activations in a TableSet.</span>
<span class="sd">            table_set: The name of the TableSet to save the results to.</span>
<span class="sd">            stim_x: The stim_x variable contains an array with, for every row in the responses, what x variables were activated at that point.</span>
<span class="sd">            stim_y: The stim_y variable contains an array with, for every row in the responses, what y variables were activated at that point.</span>
<span class="sd">            candidate_function_parameters: A numpy array with, at each row, three variables for x, y, and sigma that will be evaluated by the function.</span>
<span class="sd">            prediction_function: The function that will generate the prediction. by default this is a simple gaussian function.</span>
<span class="sd">            stimulus_description (optional): The stimulus variable is an np.ndarray with, at each row, an array with the list of stimuli that were activated at that point.</span>
<span class="sd">            parallel (optional, default=True): Boolean indicating whether the algorithm should run parallel. Parallel processing makes the algorithm a lot faster.</span>
<span class="sd">            verbose (optional, default=False): Boolean indicating whether the function prints progress to the console.</span>
<span class="sd">            dtype (optional): The data type to store the data in when storing the data in a table</span>
<span class="sd">            split_calculation (optional, default=True): Splits the task into parts to avoid overloading the memory or the CPU.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A TableSet with the goodness of fits for all nodes in the responses table. The TableSet has the same layout as the original one.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create a new Table with the shape of the original TableSet</span>
            <span class="c1"># Create tuple of Nones from the original TableSet</span>
        <span class="k">def</span> <span class="nf">tuple_of_nones_from_original_table_set</span><span class="p">(</span><span class="n">labels</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tuple_of_nones_from_original_table_set</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="n">new_table_initialisation_data</span> <span class="o">=</span> <span class="n">tuple_of_nones_from_original_table_set</span><span class="p">(</span><span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">)</span>
            <span class="c1"># Get the original ncols and nrows variables.</span>
        <span class="n">ncols</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">ncols_tuple</span>
        <span class="n">nrows</span> <span class="o">=</span> <span class="n">candidate_function_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Create the TableSet, checking if another one already exists with that name</span>
        <span class="n">new_table_set</span> <span class="o">=</span> <span class="n">TableSet</span><span class="p">(</span><span class="n">table_set</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">database</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_table_set</span><span class="o">.</span><span class="n">initialised</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;A TableSet with this name already exists! Delete it or choose another name!&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Initialising TableSet&#39;</span><span class="p">)</span>
        <span class="n">step</span> <span class="o">=</span> <span class="mi">500</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">step</span><span class="p">)):</span>
            <span class="n">new_nrows</span> <span class="o">=</span> <span class="n">step</span>
            <span class="k">if</span> <span class="n">row</span> <span class="o">+</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="n">nrows</span><span class="p">:</span>
                <span class="n">new_nrows</span> <span class="o">=</span> <span class="n">nrows</span> <span class="o">-</span> <span class="n">row</span>
            <span class="n">new_table_set</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">(</span><span class="n">new_table_initialisation_data</span><span class="p">,</span> <span class="n">table_set</span><span class="p">,</span>
                                                                       <span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">,</span>
                                                                       <span class="n">new_nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">append_rows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Run the fit response function for each subtable recursively when using splitting</span>
        <span class="k">def</span> <span class="nf">recursively_run_response_function_by_splitting</span><span class="p">(</span><span class="n">responses_in_function</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">,</span> <span class="n">parent</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">new_parent</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">parent</span><span class="si">}</span><span class="s1"> &gt; </span><span class="si">{</span><span class="n">responses_in_function</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_parent</span> <span class="o">=</span> <span class="n">responses_in_function</span><span class="o">.</span><span class="n">name</span>
            <span class="c1"># Keep track of starting column to update the TableSet</span>
            <span class="n">col_start</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">subtable</span> <span class="ow">in</span> <span class="n">responses_in_function</span><span class="o">.</span><span class="n">subtables</span><span class="p">:</span>
                <span class="n">subtable_instance</span> <span class="o">=</span> <span class="n">responses_in_function</span><span class="o">.</span><span class="n">get_subtable</span><span class="p">(</span><span class="n">subtable</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">subtable_instance</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TableSet</span><span class="p">:</span>  <span class="c1"># Use this function recursively</span>
                    <span class="n">recursively_run_response_function_by_splitting</span><span class="p">(</span><span class="n">subtable_instance</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="n">new_parent</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>  <span class="c1"># If node --&gt; Run the fit</span>
                    <span class="c1"># Print the name of the table &quot;parent &gt; child&quot;</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">new_parent</span><span class="si">}</span><span class="s1"> &gt; </span><span class="si">{</span><span class="n">subtable_instance</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                    <span class="c1"># Run the fit_response_function</span>
                    <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">subtable_instance</span><span class="p">[:]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span>
                                                         <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">prediction_function</span><span class="p">,</span>
                                                         <span class="n">stimulus_description</span><span class="o">=</span><span class="n">stimulus_description</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                                                         <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
                    <span class="c1"># Save the result of each of those things to the table</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">((</span><span class="n">results</span><span class="p">,),</span> <span class="n">table_set</span><span class="p">,</span> <span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">,</span>
                                                               <span class="n">col_start</span><span class="o">=</span><span class="n">col_start</span><span class="p">)</span>
                <span class="n">col_start</span> <span class="o">+=</span> <span class="n">subtable_instance</span><span class="o">.</span><span class="n">ncols</span>

        <span class="k">def</span> <span class="nf">run_response_function_all_at_once</span><span class="p">(</span><span class="n">responses_in_function</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">):</span>
            <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">responses_in_function</span><span class="p">[:]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span>
                                                 <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">prediction_function</span><span class="p">,</span>
                                                 <span class="n">stimulus_description</span><span class="o">=</span><span class="n">stimulus_description</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                                                 <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">((</span><span class="n">results</span><span class="p">,),</span> <span class="n">table_set</span><span class="p">,</span> <span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">,</span>
                                                       <span class="n">col_start</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running calculations&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">split_calculation</span><span class="p">:</span>
            <span class="n">recursively_run_response_function_by_splitting</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">run_response_function_all_at_once</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_table_set</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">fit_response_function</span><span class="p">(</span><span class="n">responses</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                              <span class="n">candidate_function_parameters</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                              <span class="n">prediction_function</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&quot;</span><span class="p">,</span>
                              <span class="n">stimulus_description</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                              <span class="n">parallel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                              <span class="n">dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function that uses a prediction function to generate predictions for the activations of neurons for all the</span>
<span class="sd">        candidate function parameters described in the `candidate_function_parameters` variable.</span>

<span class="sd">        By default, the prediction_function is a gaussian function. Another example of a prediction functions could be &#39;stim_x**x&#39;.</span>
<span class="sd">        At the point of executing the prediction function stim_x, stim_y, x, y, and s are the available parameters.</span>

<span class="sd">        The predictions are compared to the recorded responses to determine a goodness of fit.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.fit_response_function(np.array([[1,2,3],[1,2,3],[1,2,3]]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([1,2,3,1,2,3]), np.array([1,2,3,1,2,3]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([[1,1,1], [1,1,2], [1,1,3], [1,2,1]])</span>
<span class="sd">        &gt;&gt;&gt;                                      &#39;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&#39;)</span>
<span class="sd">        array([0.35, 0.44, 0.99])</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.fit_response_function(np.array([[1,2,3],[1,2,3],[1,2,3]]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([1,2,3,1,2,3]), np.array([0,0,0,0,0,0]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([[1,0,1], [1,0,2], [1,1,3], [2,0,1], ...]),</span>
<span class="sd">        &gt;&gt;&gt;                                      &#39;np.exp(((stim_x - x) ** 2) / (-2 * s ** 2))&#39;)</span>
<span class="sd">        array([0.35, 0.44, 0.24])</span>

<span class="sd">        Args:</span>
<span class="sd">            responses: Recorded activations</span>
<span class="sd">            stim_x: The stim_x variable contains an array with, for every row in the responses, what x variables were activated at that point.</span>
<span class="sd">            stim_y: The stim_y variable contains an array with, for every row in the responses, what y variables were activated at that point.</span>
<span class="sd">            candidate_function_parameters: A numpy array with, at each row, three variables for x, y, and sigma that will be evaluated by the function.</span>
<span class="sd">            prediction_function: The function that will generate the prediction. by default this is a simple gaussian function.</span>
<span class="sd">            stimulus_description (optional): The stimulus variable is an np.ndarray with, at each row, an array with the list of stimuli that were activated at that point.</span>
<span class="sd">            parallel (optional, default=True): Boolean indicating whether the algorithm should run parallel. Parallel processing makes the algorithm a lot faster.</span>
<span class="sd">            verbose (optional, default=False): Boolean indicating whether the function prints progress to the console.</span>
<span class="sd">            dtype (optional): The data type to store the data in when storing the data in a table</span>

<span class="sd">        Returns:</span>
<span class="sd">           np.ndarray containing the goodness of fits.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># If the stimulus is None, assume that each feature was shown once and one at the time represented by an identity matrix</span>
        <span class="k">if</span> <span class="n">stimulus_description</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">stimulus_description</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_x</span><span class="p">))</span>

        <span class="n">var_resp</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">o</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">parallel</span><span class="p">:</span>
            <span class="n">var_resp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">responses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">responses</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">responses_T</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">T</span>

        <span class="n">goodness_of_fits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">candidate_function_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">responses</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">candidate_function_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">disable</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">),</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
            <span class="n">evaluated_prediction_function</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">prediction_function</span><span class="p">)</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="p">(</span><span class="n">stimulus_description</span> <span class="o">@</span> <span class="n">evaluated_prediction_function</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">parallel</span><span class="p">:</span>
                <span class="n">_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">prediction</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">_x</span><span class="p">)</span> <span class="o">@</span> <span class="n">responses_T</span>
                <span class="n">variance_unexplained</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">responses_T</span> <span class="o">-</span> <span class="n">_x</span> <span class="o">@</span> <span class="n">scale</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">goodness_of_fit</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">variance_unexplained</span> <span class="o">/</span> <span class="n">var_resp</span><span class="p">)</span>  <span class="c1"># This is the inverted portion of the variance that is unexplained</span>
                <span class="n">goodness_of_fit</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">goodness_of_fit</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">goodness_of_fit</span><span class="p">[</span><span class="n">goodness_of_fit</span> <span class="o">==</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">goodness_of_fits</span><span class="p">[</span><span class="n">row</span><span class="p">]</span> <span class="o">=</span> <span class="n">goodness_of_fit</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">responses</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="n">goodness_of_fit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">prediction</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">responses</span><span class="p">[</span><span class="n">response</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
                    <span class="n">goodness_of_fits</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">response</span><span class="p">]</span> <span class="o">=</span> <span class="n">goodness_of_fit</span>
        <span class="k">return</span> <span class="n">goodness_of_fits</span>

    <span class="k">def</span> <span class="nf">__save__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
                 <span class="n">col_start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves the results to a TableSet.</span>

<span class="sd">        Args:</span>
<span class="sd">            table: Name of the TableSet.</span>
<span class="sd">            results: np.ndarray of the results.</span>
<span class="sd">            override: If true, overrides the existing Table/TableSet if it exists</span>
<span class="sd">            col_start: Position of the data</span>
<span class="sd">            dtype: Data type to store the data in</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">table</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="n">override</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">remove_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">((</span><span class="n">results</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">),),</span> <span class="n">table</span><span class="p">,</span> <span class="p">{</span><span class="n">table</span><span class="p">:</span> <span class="n">table</span><span class="p">},</span> <span class="n">col_start</span><span class="o">=</span><span class="n">col_start</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">generate_fake_responses</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates fake responses for the fitting test.</span>

<span class="sd">        Examples</span>
<span class="sd">        ------------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.generate_fake_responses([(1,1,2), (3,2,1)], (StimulusGenerator.stim_x, StimulusGenerator.stim_y), np.array([[0, 0, 1, 1, 0, 0], [1, 0, 1, 0, 0, 0]]))</span>
<span class="sd">        array([[1.48902756, 1.60653066],</span>
<span class="sd">               [0.44996444, 0.16417]])</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.generate_fake_responses([(2,3,1), (1,2,1)], (StimulusGenerator.stim_x, StimulusGenerator.stim_y), np.array([[0, 0, 1, 1, 0, 0], [1, 0, 1, 0, 0, 0]]))</span>
<span class="sd">        array([[0.74186594, 0.68861566],</span>
<span class="sd">               [0.9744101 , 1.21306132]])</span>

<span class="sd">        Args:</span>
<span class="sd">            variables: list of tuples containing the known variables</span>
<span class="sd">            stim_x: Stim x of the fake responses.</span>
<span class="sd">            stim_y: Stim y of the fake responses.</span>
<span class="sd">            stimulus: The stimulus of the fake responses.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray of fake responses.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nd_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">required_x</span><span class="p">,</span> <span class="n">required_y</span><span class="p">,</span> <span class="n">_required_s</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(((</span><span class="n">stim_x</span> <span class="o">-</span> <span class="n">required_x</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">stim_y</span> <span class="o">-</span> <span class="n">required_y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">_required_s</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">stimulus</span> <span class="o">@</span> <span class="n">g</span><span class="p">)</span>
            <span class="n">nd_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nd_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_response_fitting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variables_to_discover</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span>
                              <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tests the response fitting using known function parameters by generating fake responses, fitting parameters,</span>
<span class="sd">        and comparing the best fitted parameter with the known parameter.</span>

<span class="sd">        Args:</span>
<span class="sd">            variables_to_discover: list of tuples containing the known variables</span>
<span class="sd">            stimulus: The stimulus of the fake responses.</span>
<span class="sd">            stim_x: Stim x of the fake responses.</span>
<span class="sd">            stim_y: Stim y of the fake responses.</span>
<span class="sd">            candidate_function_parameters: The candidate parameters.</span>
<span class="sd">            parallel: Whether the function should use the parallel algorithm</span>
<span class="sd">            verbose: Whether the function should print progress to the command line.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray with the predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">generated_responses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_fake_responses</span><span class="p">(</span><span class="n">variables_to_discover</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">)</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">generated_responses</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">candidate_function_parameters</span><span class="p">,</span>
                                               <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_best_fits</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">predicted</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">linearise_sigma</span><span class="p">(</span><span class="n">log_sigma</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates a linear full width half maximum for a sigma variable.</span>

<span class="sd">        Examples</span>
<span class="sd">        -----------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.linearise_sigma(0.01, 3)</span>
<span class="sd">        0.07064623359911781</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.linearise_sigma(0.2, 5)</span>
<span class="sd">        2.3766436233783077</span>

<span class="sd">        Args:</span>
<span class="sd">            log_sigma: The sigma value in log space.</span>
<span class="sd">            x: The corresponding variable</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">fwhm_log</span> <span class="o">=</span> <span class="n">log_sigma</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
        <span class="n">fwhm_lin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_x</span> <span class="o">+</span> <span class="n">fwhm_log</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_x</span> <span class="o">-</span> <span class="n">fwhm_log</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fwhm_lin</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">init_parameter_set</span><span class="p">(</span><span class="n">step</span><span class="p">:</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">),</span> <span class="n">par_max</span><span class="p">:</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="n">par_min</span><span class="p">:</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span>
                           <span class="n">linearise_s</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                           <span class="n">log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialises the candidate function parameters by using the step and shape of the candidate parameters.</span>
<span class="sd">        Can linearise the sigma variable and move parameters into log space.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.init_parameter_set((1.,1.,0.1), (3.,3.,0.3), (1,1,0.1), False, False)</span>
<span class="sd">        array([[1. , 1. , 0.1],</span>
<span class="sd">               [1. , 1. , 0.2],</span>
<span class="sd">               [1. , 2. , 0.1],</span>
<span class="sd">               [1. , 2. , 0.2],</span>
<span class="sd">               [2. , 1. , 0.1],</span>
<span class="sd">               [2. , 1. , 0.2],</span>
<span class="sd">               [2. , 2. , 0.1],</span>
<span class="sd">               [2. , 2. , 0.2]], dtype=float32)</span>

<span class="sd">        Args:</span>
<span class="sd">            step: (float, float, float) The step sizes of the parameters.</span>
<span class="sd">            par_max: (int, int, int) The maximum of the parameters.</span>
<span class="sd">            par_min: (int, int, int) The minimum of the parameters.</span>
<span class="sd">            linearise_s: (bool) If true, the sigmas will get linearised.</span>
<span class="sd">            log: (bool) If true, the first two parameters are moved into log space.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray with at each row a set of parameter function parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">size</span> <span class="o">*</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
                    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                        <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">linearise_s</span><span class="p">:</span>
            <span class="n">p</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">FittingManager</span><span class="o">.</span><span class="n">linearise_sigma</span><span class="p">(</span><span class="n">p</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">p</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">p</span>


<span class="k">class</span> <span class="nc">StimulusGenerator</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class for the StimulusGenerators.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates all input and saves the input to a table.</span>

<span class="sd">        Usage</span>
<span class="sd">        ------</span>
<span class="sd">        &gt;&gt;&gt; StimulusGenerator().generate((128,160))</span>

<span class="sd">        Args:</span>
<span class="sd">            shape: The expected shape of the input</span>

<span class="sd">        Returns:</span>
<span class="sd">            Table or TableSet containing the stimuli</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">stimulus_description</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates the stimulus description for use in the `FittingManager`</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray containing the stimulus variable to be used by the FittingManager.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">stim_x</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">stim_y</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>


<span class="k">class</span> <span class="nc">InputManager</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class that manages the input and the batches.</span>
<span class="sd">    Takes an input generator as input. The generator saves the input to a table.</span>
<span class="sd">    That table is then used to determine which batches are valid and to retrieve input.</span>

<span class="sd">    Args:</span>
<span class="sd">        table: (`Table` or `TableSet`)  The table the input generator stores it&#39;s data to.</span>
<span class="sd">        shape: (tuple) A tuple of the shape of the input so it can be transformed to that.</span>
<span class="sd">        stimulus_generator: (`StimulusGenerator`) An StimulusGenerator that can generate input.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">],</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">stimulus_generator</span><span class="p">:</span> <span class="n">StimulusGenerator</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_table</span> <span class="o">=</span> <span class="n">table</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="k">if</span> <span class="n">stimulus_generator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">initialised</span><span class="p">):</span>
            <span class="n">stimulus_generator</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__prod</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The product of all iterable variables together</span>

<span class="sd">        Examples</span>
<span class="sd">        ----------</span>
<span class="sd">        &gt;&gt;&gt; __prod((1,2,3,4,5))</span>
<span class="sd">        120</span>
<span class="sd">        &gt;&gt;&gt; __prod((8, 12, 5))</span>
<span class="sd">        480</span>

<span class="sd">        Args:</span>
<span class="sd">            val: tuple</span>

<span class="sd">        Returns:</span>
<span class="sd">            The product as a float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="n">val</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">*=</span> <span class="n">ele</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">valid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determines if the batch is valid for the input table</span>

<span class="sd">        Examples</span>
<span class="sd">        ------------</span>
<span class="sd">        &gt;&gt;&gt; valid(1, 100)</span>
<span class="sd">        True</span>
<span class="sd">        &gt;&gt;&gt; valid(10, 100)</span>
<span class="sd">        False</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer of the batch that needs to be tested for validity</span>
<span class="sd">            batch_size: The size of the batches.</span>

<span class="sd">        Returns:</span>
<span class="sd">            boolean depicting the validity of the batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">nrows</span>

    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to get the input for a specific batch.</span>

<span class="sd">        Examples</span>
<span class="sd">        ----------</span>
<span class="sd">        &gt;&gt;&gt; get(0, 2)</span>
<span class="sd">        Array([</span>
<span class="sd">            [1,1,1,1,1,1,0,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...]</span>
<span class="sd">        ])</span>
<span class="sd">        &gt;&gt;&gt; get(0, 4)</span>
<span class="sd">        Array([</span>
<span class="sd">            [1,1,1,1,1,1,0,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...]</span>
<span class="sd">        ])</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer of the batch.</span>
<span class="sd">            batch_size: The size of the batch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray containing the input</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="n">batch_size</span>
        <span class="k">if</span> <span class="n">end</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">nrows</span><span class="p">:</span>
            <span class="n">end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">nrows</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">OutputManager</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The `OutputManager` is the class that goes through batches of input.</span>
<span class="sd">    The batches are retrieved from the provided `InputManager`.</span>
<span class="sd">    The results are stored using the provided `StorageManager`.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        network: The `Network` that will be used.</span>
<span class="sd">        storage_manager: The `StorageManager` that will allow for saving the results.</span>
<span class="sd">        input_manager: The `InputManager` that will provide the input</span>

<span class="sd">    Args:</span>
<span class="sd">        network: The `Network` that will be used.</span>
<span class="sd">        storage_manager: The `StorageManager` that will allow for saving the results.</span>
<span class="sd">        input_manager: The `InputManager` that will provide the input</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">Network</span><span class="p">,</span> <span class="n">storage_manager</span><span class="p">:</span> <span class="n">StorageManager</span><span class="p">,</span> <span class="n">input_manager</span><span class="p">:</span> <span class="n">InputManager</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span> <span class="o">=</span> <span class="n">storage_manager</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_manager</span> <span class="o">=</span> <span class="n">input_manager</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">resume</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function runs a batch through a `Network`</span>

<span class="sd">        Examples</span>
<span class="sd">        -----------</span>
<span class="sd">        &gt;&gt;&gt; run(&#39;TableName&#39;, 100)</span>
<span class="sd">        &gt;&gt;&gt; run(&#39;TableName&#39;, 100, resume=True, verbose=True)</span>

<span class="sd">        Args:</span>
<span class="sd">            table: `Table` to save data to</span>
<span class="sd">            batch_size: (int) Size of the batches to input into the network</span>
<span class="sd">            override (optional, default=True): (bool) determines whether the table gets extended or overridden (default=False)</span>
<span class="sd">            resume (optional, default=False): (bool) resume at last batch on failure</span>
<span class="sd">            verbose (optional, default=False): (bool) outputs the current batch and total percentage done</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">override</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">resume</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">remove_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">resume</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">tbl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">open_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tbl</span><span class="o">.</span><span class="n">initialised</span><span class="p">:</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">tbl</span><span class="o">.</span><span class="n">nrows</span><span class="o">/</span><span class="n">batch_size</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">except</span> <span class="n">NoSuchTableError</span><span class="p">:</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">batch_end</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_manager</span><span class="o">.</span><span class="n">valid</span><span class="p">(</span><span class="n">batch_end</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">batch_end</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_end</span><span class="p">),</span> <span class="n">disable</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">current_batch</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">network_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_manager</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="n">network_output</span><span class="p">,</span> <span class="n">network_output_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">network_input</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">(</span><span class="n">network_output</span><span class="p">,</span> <span class="n">table</span><span class="p">,</span> <span class="n">network_output_labels</span><span class="p">,</span> <span class="n">append_rows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">batch</span> <span class="o">+=</span> <span class="mi">1</span>


<span class="k">class</span> <span class="nc">Plot</span><span class="p">:</span>

    <span class="n">save_fig</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">save_fig_folder</span> <span class="o">=</span> <span class="s1">&#39;./&#39;</span>
    <span class="n">filetype</span> <span class="o">=</span> <span class="s1">&#39;png&#39;</span>
    <span class="n">title</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="n">plot</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">no_plotting</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;This function requires matplotlib. Please install matplotlib and try again.&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Plot</span><span class="o">.</span><span class="n">save_fig</span><span class="p">:</span>
            <span class="n">tmp_title</span> <span class="o">=</span> <span class="n">Plot</span><span class="o">.</span><span class="n">title</span> <span class="k">if</span> <span class="n">Plot</span><span class="o">.</span><span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">microsecond</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">Plot</span><span class="o">.</span><span class="n">save_fig_folder</span><span class="si">}{</span><span class="n">tmp_title</span><span class="si">}</span><span class="s1">.</span><span class="si">{</span><span class="n">Plot</span><span class="o">.</span><span class="n">filetype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="n">plot</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">plot</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
        <span class="n">Plot</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
</pre></div>

        </details>

            </section>
                <section id="Network">
                                <div class="attr class">
        <a class="headerlink" href="#Network">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">Network</span><wbr>(<span class="base">abc.ABC</span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract Network class</span>
<span class="sd">    Subclasses of this class will be the only actual interaction point between networks and the rest of the program.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        current_batch: (int) The current batch</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">current_batch</span><span class="p">:</span> <span class="nb">int</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_array</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the stimuli (in the `input_array`) through the network and returns the results.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; Network().run(np.array([[1,2,3,4], [2,3,4,5]]))</span>
<span class="sd">        (tuple of results split up in subparts for the subtable structure of the `TableSet`, dict of names for the structure of the `TableSet`.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_array: Input array containing all the stimuli in this batch</span>

<span class="sd">        Returns:</span>
<span class="sd">            The results as a tuple and the labels as a dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">is_tf_one</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Helper function for checking the TensorFlow function</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tensorflow</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&lt;=</span> <span class="s2">&quot;2&quot;</span>

    <span class="k">def</span> <span class="nf">extract_numpy_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">to_extract</span><span class="p">,</span> <span class="n">session</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        If the tensorflow version is version 1, the extraction of arrays from tensors follows a different algorithm.</span>
<span class="sd">        This function provides a universal function to perform the operation.</span>

<span class="sd">        The session is an optional variable that allows you to share the same session across different extractions</span>
<span class="sd">        saving memory.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; Network().extract_numpy_array([tf.Tensor(), tf.Tensor])</span>
<span class="sd">        [Array([]), Array([])]</span>
<span class="sd">        &gt;&gt;&gt; Network().extract_numpy_array({&#39;A&#39;: tf.Tensor(), &#39;B&#39;: tf.Tensor()})</span>
<span class="sd">        {&#39;A&#39;: Array([]), &#39;B&#39;: Array([])}</span>

<span class="sd">        Args:</span>
<span class="sd">            to_extract: The tensor or structure containing tensors that needs to be extracted. This structure can be of any type but may not contain any np.ndarrays.</span>
<span class="sd">            session (optional): The TensorFlow session.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The resulting np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tensorflow</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;tensorflow could not be imported&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tf_one</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">to_extract</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">to_extract</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">to_extract</span>
                <span class="n">tensor_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tensor_type</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">to_extract</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">(</span><span class="n">to_extract</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">session</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tensor_type</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)):</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">(</span><span class="n">to_extract</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">session</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tensor_type</span> <span class="ow">is</span> <span class="nb">tuple</span><span class="p">:</span>
                    <span class="c1"># Make a list, tuples cannot be changed</span>
                    <span class="n">new_output</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)):</span>
                        <span class="n">new_output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">(</span><span class="n">to_extract</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">session</span><span class="p">))</span>
                    <span class="k">return</span> <span class="n">new_output</span>
                <span class="k">return</span> <span class="n">output</span>
        <span class="k">if</span> <span class="n">session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
                <span class="k">return</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Abstract Network class
Subclasses of this class will be the only actual interaction point between networks and the rest of the program.</p>

<h6 id="attributes">Attributes</h6>

<ul>
<li><strong>current_batch:</strong>  (int) The current batch</li>
</ul>
</div>


                            <div id="Network.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Network.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">Network</span><span class="signature">()</span>
    </div>

        
    

                            </div>
                            <div id="Network.current_batch" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#Network.current_batch">#&nbsp;&nbsp</a>

        <span class="name">current_batch</span><span class="annotation">: int</span>
    </div>

    

                            </div>
                            <div id="Network.run" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Network.run">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">run</span><span class="signature">(
    self,
    input_array: numpy.ndarray
) -&gt; (&lt;class &#39;tuple&#39;&gt;, &lt;class &#39;dict&#39;&gt;)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_array</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the stimuli (in the `input_array`) through the network and returns the results.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; Network().run(np.array([[1,2,3,4], [2,3,4,5]]))</span>
<span class="sd">        (tuple of results split up in subparts for the subtable structure of the `TableSet`, dict of names for the structure of the `TableSet`.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_array: Input array containing all the stimuli in this batch</span>

<span class="sd">        Returns:</span>
<span class="sd">            The results as a tuple and the labels as a dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>

        </details>

            <div class="docstring"><p>Runs the stimuli (in the <code>input_array</code>) through the network and returns the results.</p>

<h2 id="examples">Examples</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">Network</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]]))</span>
<span class="go">(tuple of results split up in subparts for the subtable structure of the `TableSet`, dict of names for the structure of the `TableSet`.</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>input_array:</strong>  Input array containing all the stimuli in this batch</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>The results as a tuple and the labels as a dictionary</p>
</blockquote>
</div>


                            </div>
                            <div id="Network.is_tf_one" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Network.is_tf_one">#&nbsp;&nbsp</a>

                <div class="decorator">@staticmethod</div>

            <span class="def">def</span>
            <span class="name">is_tf_one</span><span class="signature">()</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">is_tf_one</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Helper function for checking the TensorFlow function</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tensorflow</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&lt;=</span> <span class="s2">&quot;2&quot;</span>
</pre></div>

        </details>

            <div class="docstring"><p>Helper function for checking the TensorFlow function</p>
</div>


                            </div>
                            <div id="Network.extract_numpy_array" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Network.extract_numpy_array">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">extract_numpy_array</span><span class="signature">(self, to_extract, session: Any = None)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">extract_numpy_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">to_extract</span><span class="p">,</span> <span class="n">session</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        If the tensorflow version is version 1, the extraction of arrays from tensors follows a different algorithm.</span>
<span class="sd">        This function provides a universal function to perform the operation.</span>

<span class="sd">        The session is an optional variable that allows you to share the same session across different extractions</span>
<span class="sd">        saving memory.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; Network().extract_numpy_array([tf.Tensor(), tf.Tensor])</span>
<span class="sd">        [Array([]), Array([])]</span>
<span class="sd">        &gt;&gt;&gt; Network().extract_numpy_array({&#39;A&#39;: tf.Tensor(), &#39;B&#39;: tf.Tensor()})</span>
<span class="sd">        {&#39;A&#39;: Array([]), &#39;B&#39;: Array([])}</span>

<span class="sd">        Args:</span>
<span class="sd">            to_extract: The tensor or structure containing tensors that needs to be extracted. This structure can be of any type but may not contain any np.ndarrays.</span>
<span class="sd">            session (optional): The TensorFlow session.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The resulting np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tensorflow</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;tensorflow could not be imported&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tf_one</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">to_extract</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">to_extract</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">to_extract</span>
                <span class="n">tensor_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tensor_type</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">to_extract</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">(</span><span class="n">to_extract</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">session</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tensor_type</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)):</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">(</span><span class="n">to_extract</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">session</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tensor_type</span> <span class="ow">is</span> <span class="nb">tuple</span><span class="p">:</span>
                    <span class="c1"># Make a list, tuples cannot be changed</span>
                    <span class="n">new_output</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)):</span>
                        <span class="n">new_output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">(</span><span class="n">to_extract</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">session</span><span class="p">))</span>
                    <span class="k">return</span> <span class="n">new_output</span>
                <span class="k">return</span> <span class="n">output</span>
        <span class="k">if</span> <span class="n">session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
                <span class="k">return</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">to_extract</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>If the tensorflow version is version 1, the extraction of arrays from tensors follows a different algorithm.
This function provides a universal function to perform the operation.</p>

<p>The session is an optional variable that allows you to share the same session across different extractions
saving memory.</p>

<h2 id="examples">Examples</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">Network</span><span class="p">()</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span>
<span class="go">[Array([]), Array([])]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Network</span><span class="p">()</span><span class="o">.</span><span class="n">extract_numpy_array</span><span class="p">({</span><span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(),</span> <span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">()})</span>
<span class="go">{&#39;A&#39;: Array([]), &#39;B&#39;: Array([])}</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>to_extract:</strong>  The tensor or structure containing tensors that needs to be extracted. This structure can be of any type but may not contain any np.ndarrays.</li>
<li><strong>session (optional):</strong>  The TensorFlow session.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>The resulting np.ndarray</p>
</blockquote>
</div>


                            </div>
                </section>
                <section id="FittingManager">
                                <div class="attr class">
        <a class="headerlink" href="#FittingManager">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">FittingManager</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">FittingManager</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class responsible for fitting response functions to recorded activations and calculating the best fits.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        storage_manager: StorageManager used to store the results from fittings.</span>

<span class="sd">    Args:</span>
<span class="sd">        storage_manager: StorageManager used to store the results from fittings.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">storage_manager</span><span class="p">:</span> <span class="n">StorageManager</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span> <span class="o">=</span> <span class="n">storage_manager</span>

    <span class="k">def</span> <span class="nf">calculate_best_fits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">candidate_function_parameters</span><span class="p">,</span>
                            <span class="n">table</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Use already generated results in a Table, TableSet, or np.ndarray to get the best fits from those sets.</span>
<span class="sd">        Saves those best_fits to the table.</span>

<span class="sd">        It the results are a TableSet this function will preserve the organisation of the original TableSet.</span>

<span class="sd">        Args:</span>
<span class="sd">            results: `Table`, `TableSet`, np.ndarray with results.</span>
<span class="sd">            candidate_function_parameters: The set with candidate function parameters</span>
<span class="sd">            table: Table to save the best fits to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Array with the resulting best_fits. If a table name has been provided, a TableSet with the best fits.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">best_predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">results</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">))</span>
        <span class="n">results_ndarray</span> <span class="o">=</span> <span class="n">results</span><span class="p">[:]</span>
        <span class="n">best_r2s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmax</span><span class="p">(</span><span class="n">results_ndarray</span><span class="p">[:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">results_ndarray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">best_r2</span> <span class="o">=</span> <span class="n">best_r2s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">best_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">results_ndarray</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">best_r2</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">best_x</span><span class="p">,</span> <span class="n">best_y</span><span class="p">,</span> <span class="n">best_s</span> <span class="o">=</span> <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">best_index</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> \
                                     <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">best_index</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> \
                                     <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">best_index</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
            <span class="n">best_predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_r2</span><span class="p">,</span> <span class="n">best_x</span><span class="p">,</span> <span class="n">best_y</span><span class="p">,</span> <span class="n">best_s</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">table</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TableSet</span><span class="p">:</span>
                <span class="n">table_labels</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">recurrent_subtables</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__unpack_tuple_according_to_labels</span><span class="p">(</span><span class="n">best_predicted</span><span class="p">,</span> <span class="n">results</span><span class="p">),</span>
                                                                  <span class="n">table</span><span class="p">,</span> <span class="n">table_labels</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__save__</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">best_predicted</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">best_predicted</span>

    <span class="k">def</span> <span class="nf">__unpack_tuple_according_to_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">table_set</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Takes a TableSet and a result array to split the result array into parts fitting into the provided TableSet</span>

<span class="sd">        Args:</span>
<span class="sd">            result: np.ndarray containing items from a</span>
<span class="sd">            table_set: The TableSet the results will be formed to</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple of the results split to fit the TableSet&#39;s labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Keep track of the ncols so far to determine which part of the results needs to be selected</span>
        <span class="n">ncols_so_far</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Go through the tables and subtables recursively</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">table_set</span><span class="o">.</span><span class="n">subtables</span><span class="p">:</span>
            <span class="n">subtable</span> <span class="o">=</span> <span class="n">table_set</span><span class="o">.</span><span class="n">get_subtable</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            <span class="c1"># Select the results for this subpart</span>
            <span class="n">results_selection</span> <span class="o">=</span> <span class="n">result</span><span class="p">[:,</span> <span class="n">ncols_so_far</span><span class="p">:</span><span class="n">ncols_so_far</span><span class="o">+</span><span class="n">subtable</span><span class="o">.</span><span class="n">ncols</span><span class="p">]</span>
            <span class="c1"># Either recursively enter the subtableset or add the results selection directly</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">subtable</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TableSet</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__unpack_tuple_according_to_labels</span><span class="p">(</span><span class="n">results_selection</span><span class="p">,</span>
                                                                       <span class="n">subtable</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">results_selection</span><span class="p">)</span>
            <span class="c1"># Update the counters</span>
            <span class="n">ncols_so_far</span> <span class="o">+=</span> <span class="n">subtable</span><span class="o">.</span><span class="n">ncols</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Return the results as a tuple</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit_response_function_on_table_set</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">responses</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">,</span> <span class="n">table_set</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                                           <span class="n">candidate_function_parameters</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                                           <span class="n">prediction_function</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&quot;</span><span class="p">,</span>
                                           <span class="n">stimulus_description</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">parallel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                           <span class="n">dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">split_calculation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a new TableSet based on the input TableSet.</span>
<span class="sd">        Uses the fit response function to calculate the goodness of fit for all recorded nodes in the responses TableSet.</span>
<span class="sd">        This can be done in a, less computationally intensive, way by setting split_calculation to True.</span>
<span class="sd">        Then the program will go through the activations one subtable (not subtableset) of the responses TableSet at the time.</span>

<span class="sd">        Besides that the function has the necessary parameters for the `fit_response_function`.</span>
<span class="sd">        The `fit_response_function` is a function that uses a prediction function to generate predictions for the activations of neurons for all the</span>
<span class="sd">        candidate function parameters described in the `candidate_function_parameters` variable.</span>

<span class="sd">        By default, the prediction_function is a gaussian function. Another example of a prediction functions could be &#39;stim_x**x&#39;.</span>
<span class="sd">        At the point of executing the prediction function stim_x, stim_y, x, y, and s are the available parameters.</span>

<span class="sd">        The predictions are compared to the recorded responses to determine a goodness of fit.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        fit_response_function : The function this function uses. This function&#39;s documentation also contains some examples of input.</span>

<span class="sd">        Args:</span>
<span class="sd">            responses: Recorded activations in a TableSet.</span>
<span class="sd">            table_set: The name of the TableSet to save the results to.</span>
<span class="sd">            stim_x: The stim_x variable contains an array with, for every row in the responses, what x variables were activated at that point.</span>
<span class="sd">            stim_y: The stim_y variable contains an array with, for every row in the responses, what y variables were activated at that point.</span>
<span class="sd">            candidate_function_parameters: A numpy array with, at each row, three variables for x, y, and sigma that will be evaluated by the function.</span>
<span class="sd">            prediction_function: The function that will generate the prediction. by default this is a simple gaussian function.</span>
<span class="sd">            stimulus_description (optional): The stimulus variable is an np.ndarray with, at each row, an array with the list of stimuli that were activated at that point.</span>
<span class="sd">            parallel (optional, default=True): Boolean indicating whether the algorithm should run parallel. Parallel processing makes the algorithm a lot faster.</span>
<span class="sd">            verbose (optional, default=False): Boolean indicating whether the function prints progress to the console.</span>
<span class="sd">            dtype (optional): The data type to store the data in when storing the data in a table</span>
<span class="sd">            split_calculation (optional, default=True): Splits the task into parts to avoid overloading the memory or the CPU.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A TableSet with the goodness of fits for all nodes in the responses table. The TableSet has the same layout as the original one.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create a new Table with the shape of the original TableSet</span>
            <span class="c1"># Create tuple of Nones from the original TableSet</span>
        <span class="k">def</span> <span class="nf">tuple_of_nones_from_original_table_set</span><span class="p">(</span><span class="n">labels</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tuple_of_nones_from_original_table_set</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="n">new_table_initialisation_data</span> <span class="o">=</span> <span class="n">tuple_of_nones_from_original_table_set</span><span class="p">(</span><span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">)</span>
            <span class="c1"># Get the original ncols and nrows variables.</span>
        <span class="n">ncols</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">ncols_tuple</span>
        <span class="n">nrows</span> <span class="o">=</span> <span class="n">candidate_function_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Create the TableSet, checking if another one already exists with that name</span>
        <span class="n">new_table_set</span> <span class="o">=</span> <span class="n">TableSet</span><span class="p">(</span><span class="n">table_set</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">database</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_table_set</span><span class="o">.</span><span class="n">initialised</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;A TableSet with this name already exists! Delete it or choose another name!&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Initialising TableSet&#39;</span><span class="p">)</span>
        <span class="n">step</span> <span class="o">=</span> <span class="mi">500</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">step</span><span class="p">)):</span>
            <span class="n">new_nrows</span> <span class="o">=</span> <span class="n">step</span>
            <span class="k">if</span> <span class="n">row</span> <span class="o">+</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="n">nrows</span><span class="p">:</span>
                <span class="n">new_nrows</span> <span class="o">=</span> <span class="n">nrows</span> <span class="o">-</span> <span class="n">row</span>
            <span class="n">new_table_set</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">(</span><span class="n">new_table_initialisation_data</span><span class="p">,</span> <span class="n">table_set</span><span class="p">,</span>
                                                                       <span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">,</span>
                                                                       <span class="n">new_nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">append_rows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Run the fit response function for each subtable recursively when using splitting</span>
        <span class="k">def</span> <span class="nf">recursively_run_response_function_by_splitting</span><span class="p">(</span><span class="n">responses_in_function</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">,</span> <span class="n">parent</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">new_parent</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">parent</span><span class="si">}</span><span class="s1"> &gt; </span><span class="si">{</span><span class="n">responses_in_function</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_parent</span> <span class="o">=</span> <span class="n">responses_in_function</span><span class="o">.</span><span class="n">name</span>
            <span class="c1"># Keep track of starting column to update the TableSet</span>
            <span class="n">col_start</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">subtable</span> <span class="ow">in</span> <span class="n">responses_in_function</span><span class="o">.</span><span class="n">subtables</span><span class="p">:</span>
                <span class="n">subtable_instance</span> <span class="o">=</span> <span class="n">responses_in_function</span><span class="o">.</span><span class="n">get_subtable</span><span class="p">(</span><span class="n">subtable</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">subtable_instance</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TableSet</span><span class="p">:</span>  <span class="c1"># Use this function recursively</span>
                    <span class="n">recursively_run_response_function_by_splitting</span><span class="p">(</span><span class="n">subtable_instance</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="n">new_parent</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>  <span class="c1"># If node --&gt; Run the fit</span>
                    <span class="c1"># Print the name of the table &quot;parent &gt; child&quot;</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">new_parent</span><span class="si">}</span><span class="s1"> &gt; </span><span class="si">{</span><span class="n">subtable_instance</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                    <span class="c1"># Run the fit_response_function</span>
                    <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">subtable_instance</span><span class="p">[:]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span>
                                                         <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">prediction_function</span><span class="p">,</span>
                                                         <span class="n">stimulus_description</span><span class="o">=</span><span class="n">stimulus_description</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                                                         <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
                    <span class="c1"># Save the result of each of those things to the table</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">((</span><span class="n">results</span><span class="p">,),</span> <span class="n">table_set</span><span class="p">,</span> <span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">,</span>
                                                               <span class="n">col_start</span><span class="o">=</span><span class="n">col_start</span><span class="p">)</span>
                <span class="n">col_start</span> <span class="o">+=</span> <span class="n">subtable_instance</span><span class="o">.</span><span class="n">ncols</span>

        <span class="k">def</span> <span class="nf">run_response_function_all_at_once</span><span class="p">(</span><span class="n">responses_in_function</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">):</span>
            <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">responses_in_function</span><span class="p">[:]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span>
                                                 <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">prediction_function</span><span class="p">,</span>
                                                 <span class="n">stimulus_description</span><span class="o">=</span><span class="n">stimulus_description</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                                                 <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">((</span><span class="n">results</span><span class="p">,),</span> <span class="n">table_set</span><span class="p">,</span> <span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">,</span>
                                                       <span class="n">col_start</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running calculations&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">split_calculation</span><span class="p">:</span>
            <span class="n">recursively_run_response_function_by_splitting</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">run_response_function_all_at_once</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_table_set</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">fit_response_function</span><span class="p">(</span><span class="n">responses</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                              <span class="n">candidate_function_parameters</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                              <span class="n">prediction_function</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&quot;</span><span class="p">,</span>
                              <span class="n">stimulus_description</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                              <span class="n">parallel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                              <span class="n">dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function that uses a prediction function to generate predictions for the activations of neurons for all the</span>
<span class="sd">        candidate function parameters described in the `candidate_function_parameters` variable.</span>

<span class="sd">        By default, the prediction_function is a gaussian function. Another example of a prediction functions could be &#39;stim_x**x&#39;.</span>
<span class="sd">        At the point of executing the prediction function stim_x, stim_y, x, y, and s are the available parameters.</span>

<span class="sd">        The predictions are compared to the recorded responses to determine a goodness of fit.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.fit_response_function(np.array([[1,2,3],[1,2,3],[1,2,3]]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([1,2,3,1,2,3]), np.array([1,2,3,1,2,3]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([[1,1,1], [1,1,2], [1,1,3], [1,2,1]])</span>
<span class="sd">        &gt;&gt;&gt;                                      &#39;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&#39;)</span>
<span class="sd">        array([0.35, 0.44, 0.99])</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.fit_response_function(np.array([[1,2,3],[1,2,3],[1,2,3]]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([1,2,3,1,2,3]), np.array([0,0,0,0,0,0]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([[1,0,1], [1,0,2], [1,1,3], [2,0,1], ...]),</span>
<span class="sd">        &gt;&gt;&gt;                                      &#39;np.exp(((stim_x - x) ** 2) / (-2 * s ** 2))&#39;)</span>
<span class="sd">        array([0.35, 0.44, 0.24])</span>

<span class="sd">        Args:</span>
<span class="sd">            responses: Recorded activations</span>
<span class="sd">            stim_x: The stim_x variable contains an array with, for every row in the responses, what x variables were activated at that point.</span>
<span class="sd">            stim_y: The stim_y variable contains an array with, for every row in the responses, what y variables were activated at that point.</span>
<span class="sd">            candidate_function_parameters: A numpy array with, at each row, three variables for x, y, and sigma that will be evaluated by the function.</span>
<span class="sd">            prediction_function: The function that will generate the prediction. by default this is a simple gaussian function.</span>
<span class="sd">            stimulus_description (optional): The stimulus variable is an np.ndarray with, at each row, an array with the list of stimuli that were activated at that point.</span>
<span class="sd">            parallel (optional, default=True): Boolean indicating whether the algorithm should run parallel. Parallel processing makes the algorithm a lot faster.</span>
<span class="sd">            verbose (optional, default=False): Boolean indicating whether the function prints progress to the console.</span>
<span class="sd">            dtype (optional): The data type to store the data in when storing the data in a table</span>

<span class="sd">        Returns:</span>
<span class="sd">           np.ndarray containing the goodness of fits.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># If the stimulus is None, assume that each feature was shown once and one at the time represented by an identity matrix</span>
        <span class="k">if</span> <span class="n">stimulus_description</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">stimulus_description</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_x</span><span class="p">))</span>

        <span class="n">var_resp</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">o</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">parallel</span><span class="p">:</span>
            <span class="n">var_resp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">responses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">responses</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">responses_T</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">T</span>

        <span class="n">goodness_of_fits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">candidate_function_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">responses</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">candidate_function_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">disable</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">),</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
            <span class="n">evaluated_prediction_function</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">prediction_function</span><span class="p">)</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="p">(</span><span class="n">stimulus_description</span> <span class="o">@</span> <span class="n">evaluated_prediction_function</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">parallel</span><span class="p">:</span>
                <span class="n">_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">prediction</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">_x</span><span class="p">)</span> <span class="o">@</span> <span class="n">responses_T</span>
                <span class="n">variance_unexplained</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">responses_T</span> <span class="o">-</span> <span class="n">_x</span> <span class="o">@</span> <span class="n">scale</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">goodness_of_fit</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">variance_unexplained</span> <span class="o">/</span> <span class="n">var_resp</span><span class="p">)</span>  <span class="c1"># This is the inverted portion of the variance that is unexplained</span>
                <span class="n">goodness_of_fit</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">goodness_of_fit</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">goodness_of_fit</span><span class="p">[</span><span class="n">goodness_of_fit</span> <span class="o">==</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">goodness_of_fits</span><span class="p">[</span><span class="n">row</span><span class="p">]</span> <span class="o">=</span> <span class="n">goodness_of_fit</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">responses</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="n">goodness_of_fit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">prediction</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">responses</span><span class="p">[</span><span class="n">response</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
                    <span class="n">goodness_of_fits</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">response</span><span class="p">]</span> <span class="o">=</span> <span class="n">goodness_of_fit</span>
        <span class="k">return</span> <span class="n">goodness_of_fits</span>

    <span class="k">def</span> <span class="nf">__save__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
                 <span class="n">col_start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves the results to a TableSet.</span>

<span class="sd">        Args:</span>
<span class="sd">            table: Name of the TableSet.</span>
<span class="sd">            results: np.ndarray of the results.</span>
<span class="sd">            override: If true, overrides the existing Table/TableSet if it exists</span>
<span class="sd">            col_start: Position of the data</span>
<span class="sd">            dtype: Data type to store the data in</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">table</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="n">override</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">remove_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">((</span><span class="n">results</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">),),</span> <span class="n">table</span><span class="p">,</span> <span class="p">{</span><span class="n">table</span><span class="p">:</span> <span class="n">table</span><span class="p">},</span> <span class="n">col_start</span><span class="o">=</span><span class="n">col_start</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">generate_fake_responses</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates fake responses for the fitting test.</span>

<span class="sd">        Examples</span>
<span class="sd">        ------------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.generate_fake_responses([(1,1,2), (3,2,1)], (StimulusGenerator.stim_x, StimulusGenerator.stim_y), np.array([[0, 0, 1, 1, 0, 0], [1, 0, 1, 0, 0, 0]]))</span>
<span class="sd">        array([[1.48902756, 1.60653066],</span>
<span class="sd">               [0.44996444, 0.16417]])</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.generate_fake_responses([(2,3,1), (1,2,1)], (StimulusGenerator.stim_x, StimulusGenerator.stim_y), np.array([[0, 0, 1, 1, 0, 0], [1, 0, 1, 0, 0, 0]]))</span>
<span class="sd">        array([[0.74186594, 0.68861566],</span>
<span class="sd">               [0.9744101 , 1.21306132]])</span>

<span class="sd">        Args:</span>
<span class="sd">            variables: list of tuples containing the known variables</span>
<span class="sd">            stim_x: Stim x of the fake responses.</span>
<span class="sd">            stim_y: Stim y of the fake responses.</span>
<span class="sd">            stimulus: The stimulus of the fake responses.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray of fake responses.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nd_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">required_x</span><span class="p">,</span> <span class="n">required_y</span><span class="p">,</span> <span class="n">_required_s</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(((</span><span class="n">stim_x</span> <span class="o">-</span> <span class="n">required_x</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">stim_y</span> <span class="o">-</span> <span class="n">required_y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">_required_s</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">stimulus</span> <span class="o">@</span> <span class="n">g</span><span class="p">)</span>
            <span class="n">nd_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nd_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_response_fitting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variables_to_discover</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span>
                              <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tests the response fitting using known function parameters by generating fake responses, fitting parameters,</span>
<span class="sd">        and comparing the best fitted parameter with the known parameter.</span>

<span class="sd">        Args:</span>
<span class="sd">            variables_to_discover: list of tuples containing the known variables</span>
<span class="sd">            stimulus: The stimulus of the fake responses.</span>
<span class="sd">            stim_x: Stim x of the fake responses.</span>
<span class="sd">            stim_y: Stim y of the fake responses.</span>
<span class="sd">            candidate_function_parameters: The candidate parameters.</span>
<span class="sd">            parallel: Whether the function should use the parallel algorithm</span>
<span class="sd">            verbose: Whether the function should print progress to the command line.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray with the predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">generated_responses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_fake_responses</span><span class="p">(</span><span class="n">variables_to_discover</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">)</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">generated_responses</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">candidate_function_parameters</span><span class="p">,</span>
                                               <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_best_fits</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">predicted</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">linearise_sigma</span><span class="p">(</span><span class="n">log_sigma</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates a linear full width half maximum for a sigma variable.</span>

<span class="sd">        Examples</span>
<span class="sd">        -----------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.linearise_sigma(0.01, 3)</span>
<span class="sd">        0.07064623359911781</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.linearise_sigma(0.2, 5)</span>
<span class="sd">        2.3766436233783077</span>

<span class="sd">        Args:</span>
<span class="sd">            log_sigma: The sigma value in log space.</span>
<span class="sd">            x: The corresponding variable</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">fwhm_log</span> <span class="o">=</span> <span class="n">log_sigma</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
        <span class="n">fwhm_lin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_x</span> <span class="o">+</span> <span class="n">fwhm_log</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_x</span> <span class="o">-</span> <span class="n">fwhm_log</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fwhm_lin</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">init_parameter_set</span><span class="p">(</span><span class="n">step</span><span class="p">:</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">),</span> <span class="n">par_max</span><span class="p">:</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="n">par_min</span><span class="p">:</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span>
                           <span class="n">linearise_s</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                           <span class="n">log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialises the candidate function parameters by using the step and shape of the candidate parameters.</span>
<span class="sd">        Can linearise the sigma variable and move parameters into log space.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.init_parameter_set((1.,1.,0.1), (3.,3.,0.3), (1,1,0.1), False, False)</span>
<span class="sd">        array([[1. , 1. , 0.1],</span>
<span class="sd">               [1. , 1. , 0.2],</span>
<span class="sd">               [1. , 2. , 0.1],</span>
<span class="sd">               [1. , 2. , 0.2],</span>
<span class="sd">               [2. , 1. , 0.1],</span>
<span class="sd">               [2. , 1. , 0.2],</span>
<span class="sd">               [2. , 2. , 0.1],</span>
<span class="sd">               [2. , 2. , 0.2]], dtype=float32)</span>

<span class="sd">        Args:</span>
<span class="sd">            step: (float, float, float) The step sizes of the parameters.</span>
<span class="sd">            par_max: (int, int, int) The maximum of the parameters.</span>
<span class="sd">            par_min: (int, int, int) The minimum of the parameters.</span>
<span class="sd">            linearise_s: (bool) If true, the sigmas will get linearised.</span>
<span class="sd">            log: (bool) If true, the first two parameters are moved into log space.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray with at each row a set of parameter function parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">size</span> <span class="o">*</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
                    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                        <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">linearise_s</span><span class="p">:</span>
            <span class="n">p</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">FittingManager</span><span class="o">.</span><span class="n">linearise_sigma</span><span class="p">(</span><span class="n">p</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">p</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">p</span>
</pre></div>

        </details>

            <div class="docstring"><p>Class responsible for fitting response functions to recorded activations and calculating the best fits.</p>

<h6 id="attributes">Attributes</h6>

<ul>
<li><strong>storage_manager:</strong>  StorageManager used to store the results from fittings.</li>
</ul>

<h6 id="args">Args</h6>

<ul>
<li><strong>storage_manager:</strong>  StorageManager used to store the results from fittings.</li>
</ul>
</div>


                            <div id="FittingManager.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FittingManager.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">FittingManager</span><span class="signature">(storage_manager: <a href="nn_analysis/storage.html#StorageManager">nn_analysis.storage.StorageManager</a>)</span>
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">storage_manager</span><span class="p">:</span> <span class="n">StorageManager</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span> <span class="o">=</span> <span class="n">storage_manager</span>
</pre></div>

        </details>

    

                            </div>
                            <div id="FittingManager.calculate_best_fits" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FittingManager.calculate_best_fits">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">calculate_best_fits</span><span class="signature">(
    self,
    results: Union[<a href="nn_analysis/storage.html#Table">nn_analysis.storage.Table</a>, <a href="nn_analysis/storage.html#TableSet">nn_analysis.storage.TableSet</a>, numpy.ndarray],
    candidate_function_parameters,
    table: str = None
)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">calculate_best_fits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">candidate_function_parameters</span><span class="p">,</span>
                            <span class="n">table</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Use already generated results in a Table, TableSet, or np.ndarray to get the best fits from those sets.</span>
<span class="sd">        Saves those best_fits to the table.</span>

<span class="sd">        It the results are a TableSet this function will preserve the organisation of the original TableSet.</span>

<span class="sd">        Args:</span>
<span class="sd">            results: `Table`, `TableSet`, np.ndarray with results.</span>
<span class="sd">            candidate_function_parameters: The set with candidate function parameters</span>
<span class="sd">            table: Table to save the best fits to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Array with the resulting best_fits. If a table name has been provided, a TableSet with the best fits.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">best_predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">results</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">))</span>
        <span class="n">results_ndarray</span> <span class="o">=</span> <span class="n">results</span><span class="p">[:]</span>
        <span class="n">best_r2s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmax</span><span class="p">(</span><span class="n">results_ndarray</span><span class="p">[:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">results_ndarray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">best_r2</span> <span class="o">=</span> <span class="n">best_r2s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">best_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">results_ndarray</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">best_r2</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">best_x</span><span class="p">,</span> <span class="n">best_y</span><span class="p">,</span> <span class="n">best_s</span> <span class="o">=</span> <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">best_index</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> \
                                     <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">best_index</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> \
                                     <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">best_index</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
            <span class="n">best_predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_r2</span><span class="p">,</span> <span class="n">best_x</span><span class="p">,</span> <span class="n">best_y</span><span class="p">,</span> <span class="n">best_s</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">table</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TableSet</span><span class="p">:</span>
                <span class="n">table_labels</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">recurrent_subtables</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__unpack_tuple_according_to_labels</span><span class="p">(</span><span class="n">best_predicted</span><span class="p">,</span> <span class="n">results</span><span class="p">),</span>
                                                                  <span class="n">table</span><span class="p">,</span> <span class="n">table_labels</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__save__</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">best_predicted</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">best_predicted</span>
</pre></div>

        </details>

            <div class="docstring"><p>Use already generated results in a Table, TableSet, or np.ndarray to get the best fits from those sets.
Saves those best_fits to the table.</p>

<p>It the results are a TableSet this function will preserve the organisation of the original TableSet.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>results:</strong>  <code>Table</code>, <code>TableSet</code>, np.ndarray with results.</li>
<li><strong>candidate_function_parameters:</strong>  The set with candidate function parameters</li>
<li><strong>table:</strong>  Table to save the best fits to.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>Array with the resulting best_fits. If a table name has been provided, a TableSet with the best fits.</p>
</blockquote>
</div>


                            </div>
                            <div id="FittingManager.fit_response_function_on_table_set" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FittingManager.fit_response_function_on_table_set">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">fit_response_function_on_table_set</span><span class="signature">(
    self,
    responses: <a href="nn_analysis/storage.html#TableSet">nn_analysis.storage.TableSet</a>,
    table_set: str,
    stim_x: numpy.ndarray,
    stim_y: numpy.ndarray,
    candidate_function_parameters: numpy.ndarray,
    prediction_function: str = &#39;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&#39;,
    stimulus_description: numpy.ndarray = None,
    parallel: bool = True,
    verbose: bool = False,
    dtype: numpy.dtype = None,
    split_calculation: bool = True
)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">fit_response_function_on_table_set</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">responses</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">,</span> <span class="n">table_set</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                                           <span class="n">candidate_function_parameters</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                                           <span class="n">prediction_function</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&quot;</span><span class="p">,</span>
                                           <span class="n">stimulus_description</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">parallel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                           <span class="n">dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">split_calculation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a new TableSet based on the input TableSet.</span>
<span class="sd">        Uses the fit response function to calculate the goodness of fit for all recorded nodes in the responses TableSet.</span>
<span class="sd">        This can be done in a, less computationally intensive, way by setting split_calculation to True.</span>
<span class="sd">        Then the program will go through the activations one subtable (not subtableset) of the responses TableSet at the time.</span>

<span class="sd">        Besides that the function has the necessary parameters for the `fit_response_function`.</span>
<span class="sd">        The `fit_response_function` is a function that uses a prediction function to generate predictions for the activations of neurons for all the</span>
<span class="sd">        candidate function parameters described in the `candidate_function_parameters` variable.</span>

<span class="sd">        By default, the prediction_function is a gaussian function. Another example of a prediction functions could be &#39;stim_x**x&#39;.</span>
<span class="sd">        At the point of executing the prediction function stim_x, stim_y, x, y, and s are the available parameters.</span>

<span class="sd">        The predictions are compared to the recorded responses to determine a goodness of fit.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        fit_response_function : The function this function uses. This function&#39;s documentation also contains some examples of input.</span>

<span class="sd">        Args:</span>
<span class="sd">            responses: Recorded activations in a TableSet.</span>
<span class="sd">            table_set: The name of the TableSet to save the results to.</span>
<span class="sd">            stim_x: The stim_x variable contains an array with, for every row in the responses, what x variables were activated at that point.</span>
<span class="sd">            stim_y: The stim_y variable contains an array with, for every row in the responses, what y variables were activated at that point.</span>
<span class="sd">            candidate_function_parameters: A numpy array with, at each row, three variables for x, y, and sigma that will be evaluated by the function.</span>
<span class="sd">            prediction_function: The function that will generate the prediction. by default this is a simple gaussian function.</span>
<span class="sd">            stimulus_description (optional): The stimulus variable is an np.ndarray with, at each row, an array with the list of stimuli that were activated at that point.</span>
<span class="sd">            parallel (optional, default=True): Boolean indicating whether the algorithm should run parallel. Parallel processing makes the algorithm a lot faster.</span>
<span class="sd">            verbose (optional, default=False): Boolean indicating whether the function prints progress to the console.</span>
<span class="sd">            dtype (optional): The data type to store the data in when storing the data in a table</span>
<span class="sd">            split_calculation (optional, default=True): Splits the task into parts to avoid overloading the memory or the CPU.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A TableSet with the goodness of fits for all nodes in the responses table. The TableSet has the same layout as the original one.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create a new Table with the shape of the original TableSet</span>
            <span class="c1"># Create tuple of Nones from the original TableSet</span>
        <span class="k">def</span> <span class="nf">tuple_of_nones_from_original_table_set</span><span class="p">(</span><span class="n">labels</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tuple_of_nones_from_original_table_set</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="n">new_table_initialisation_data</span> <span class="o">=</span> <span class="n">tuple_of_nones_from_original_table_set</span><span class="p">(</span><span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">)</span>
            <span class="c1"># Get the original ncols and nrows variables.</span>
        <span class="n">ncols</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">ncols_tuple</span>
        <span class="n">nrows</span> <span class="o">=</span> <span class="n">candidate_function_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Create the TableSet, checking if another one already exists with that name</span>
        <span class="n">new_table_set</span> <span class="o">=</span> <span class="n">TableSet</span><span class="p">(</span><span class="n">table_set</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">database</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_table_set</span><span class="o">.</span><span class="n">initialised</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;A TableSet with this name already exists! Delete it or choose another name!&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Initialising TableSet&#39;</span><span class="p">)</span>
        <span class="n">step</span> <span class="o">=</span> <span class="mi">500</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">step</span><span class="p">)):</span>
            <span class="n">new_nrows</span> <span class="o">=</span> <span class="n">step</span>
            <span class="k">if</span> <span class="n">row</span> <span class="o">+</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="n">nrows</span><span class="p">:</span>
                <span class="n">new_nrows</span> <span class="o">=</span> <span class="n">nrows</span> <span class="o">-</span> <span class="n">row</span>
            <span class="n">new_table_set</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">(</span><span class="n">new_table_initialisation_data</span><span class="p">,</span> <span class="n">table_set</span><span class="p">,</span>
                                                                       <span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">,</span>
                                                                       <span class="n">new_nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">append_rows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Run the fit response function for each subtable recursively when using splitting</span>
        <span class="k">def</span> <span class="nf">recursively_run_response_function_by_splitting</span><span class="p">(</span><span class="n">responses_in_function</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">,</span> <span class="n">parent</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">new_parent</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">parent</span><span class="si">}</span><span class="s1"> &gt; </span><span class="si">{</span><span class="n">responses_in_function</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_parent</span> <span class="o">=</span> <span class="n">responses_in_function</span><span class="o">.</span><span class="n">name</span>
            <span class="c1"># Keep track of starting column to update the TableSet</span>
            <span class="n">col_start</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">subtable</span> <span class="ow">in</span> <span class="n">responses_in_function</span><span class="o">.</span><span class="n">subtables</span><span class="p">:</span>
                <span class="n">subtable_instance</span> <span class="o">=</span> <span class="n">responses_in_function</span><span class="o">.</span><span class="n">get_subtable</span><span class="p">(</span><span class="n">subtable</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">subtable_instance</span><span class="p">)</span> <span class="ow">is</span> <span class="n">TableSet</span><span class="p">:</span>  <span class="c1"># Use this function recursively</span>
                    <span class="n">recursively_run_response_function_by_splitting</span><span class="p">(</span><span class="n">subtable_instance</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="n">new_parent</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>  <span class="c1"># If node --&gt; Run the fit</span>
                    <span class="c1"># Print the name of the table &quot;parent &gt; child&quot;</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">new_parent</span><span class="si">}</span><span class="s1"> &gt; </span><span class="si">{</span><span class="n">subtable_instance</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                    <span class="c1"># Run the fit_response_function</span>
                    <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">subtable_instance</span><span class="p">[:]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span>
                                                         <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">prediction_function</span><span class="p">,</span>
                                                         <span class="n">stimulus_description</span><span class="o">=</span><span class="n">stimulus_description</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                                                         <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
                    <span class="c1"># Save the result of each of those things to the table</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">((</span><span class="n">results</span><span class="p">,),</span> <span class="n">table_set</span><span class="p">,</span> <span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">,</span>
                                                               <span class="n">col_start</span><span class="o">=</span><span class="n">col_start</span><span class="p">)</span>
                <span class="n">col_start</span> <span class="o">+=</span> <span class="n">subtable_instance</span><span class="o">.</span><span class="n">ncols</span>

        <span class="k">def</span> <span class="nf">run_response_function_all_at_once</span><span class="p">(</span><span class="n">responses_in_function</span><span class="p">:</span> <span class="n">TableSet</span><span class="p">):</span>
            <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">responses_in_function</span><span class="p">[:]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span>
                                                 <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">prediction_function</span><span class="p">,</span>
                                                 <span class="n">stimulus_description</span><span class="o">=</span><span class="n">stimulus_description</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                                                 <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">((</span><span class="n">results</span><span class="p">,),</span> <span class="n">table_set</span><span class="p">,</span> <span class="n">responses</span><span class="o">.</span><span class="n">recurrent_subtables</span><span class="p">,</span>
                                                       <span class="n">col_start</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running calculations&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">split_calculation</span><span class="p">:</span>
            <span class="n">recursively_run_response_function_by_splitting</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">run_response_function_all_at_once</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_table_set</span>
</pre></div>

        </details>

            <div class="docstring"><p>Creates a new TableSet based on the input TableSet.
Uses the fit response function to calculate the goodness of fit for all recorded nodes in the responses TableSet.
This can be done in a, less computationally intensive, way by setting split_calculation to True.
Then the program will go through the activations one subtable (not subtableset) of the responses TableSet at the time.</p>

<p>Besides that the function has the necessary parameters for the <code><a href="#FittingManager.fit_response_function">fit_response_function</a></code>.
The <code><a href="#FittingManager.fit_response_function">fit_response_function</a></code> is a function that uses a prediction function to generate predictions for the activations of neurons for all the
candidate function parameters described in the <code>candidate_function_parameters</code> variable.</p>

<p>By default, the prediction_function is a gaussian function. Another example of a prediction functions could be 'stim_x**x'.
At the point of executing the prediction function stim_x, stim_y, x, y, and s are the available parameters.</p>

<p>The predictions are compared to the recorded responses to determine a goodness of fit.</p>

<h2 id="see-also">See Also</h2>

<p>fit_response_function : The function this function uses. This function's documentation also contains some examples of input.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>responses:</strong>  Recorded activations in a TableSet.</li>
<li><strong>table_set:</strong>  The name of the TableSet to save the results to.</li>
<li><strong>stim_x:</strong>  The stim_x variable contains an array with, for every row in the responses, what x variables were activated at that point.</li>
<li><strong>stim_y:</strong>  The stim_y variable contains an array with, for every row in the responses, what y variables were activated at that point.</li>
<li><strong>candidate_function_parameters:</strong>  A numpy array with, at each row, three variables for x, y, and sigma that will be evaluated by the function.</li>
<li><strong>prediction_function:</strong>  The function that will generate the prediction. by default this is a simple gaussian function.</li>
<li><strong>stimulus_description (optional):</strong>  The stimulus variable is an np.ndarray with, at each row, an array with the list of stimuli that were activated at that point.</li>
<li><strong>parallel (optional, default=True):</strong>  Boolean indicating whether the algorithm should run parallel. Parallel processing makes the algorithm a lot faster.</li>
<li><strong>verbose (optional, default=False):</strong>  Boolean indicating whether the function prints progress to the console.</li>
<li><strong>dtype (optional):</strong>  The data type to store the data in when storing the data in a table</li>
<li><strong>split_calculation (optional, default=True):</strong>  Splits the task into parts to avoid overloading the memory or the CPU.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>A TableSet with the goodness of fits for all nodes in the responses table. The TableSet has the same layout as the original one.</p>
</blockquote>
</div>


                            </div>
                            <div id="FittingManager.fit_response_function" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FittingManager.fit_response_function">#&nbsp;&nbsp</a>

                <div class="decorator">@staticmethod</div>

            <span class="def">def</span>
            <span class="name">fit_response_function</span><span class="signature">(
    responses: numpy.ndarray,
    stim_x: numpy.ndarray,
    stim_y: numpy.ndarray,
    candidate_function_parameters: numpy.ndarray,
    prediction_function: str = &#39;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&#39;,
    stimulus_description: numpy.ndarray = None,
    parallel: bool = True,
    verbose: bool = False,
    dtype: numpy.dtype = None
) -&gt; numpy.ndarray</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">fit_response_function</span><span class="p">(</span><span class="n">responses</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                              <span class="n">candidate_function_parameters</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                              <span class="n">prediction_function</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&quot;</span><span class="p">,</span>
                              <span class="n">stimulus_description</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                              <span class="n">parallel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                              <span class="n">dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function that uses a prediction function to generate predictions for the activations of neurons for all the</span>
<span class="sd">        candidate function parameters described in the `candidate_function_parameters` variable.</span>

<span class="sd">        By default, the prediction_function is a gaussian function. Another example of a prediction functions could be &#39;stim_x**x&#39;.</span>
<span class="sd">        At the point of executing the prediction function stim_x, stim_y, x, y, and s are the available parameters.</span>

<span class="sd">        The predictions are compared to the recorded responses to determine a goodness of fit.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.fit_response_function(np.array([[1,2,3],[1,2,3],[1,2,3]]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([1,2,3,1,2,3]), np.array([1,2,3,1,2,3]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([[1,1,1], [1,1,2], [1,1,3], [1,2,1]])</span>
<span class="sd">        &gt;&gt;&gt;                                      &#39;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&#39;)</span>
<span class="sd">        array([0.35, 0.44, 0.99])</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.fit_response_function(np.array([[1,2,3],[1,2,3],[1,2,3]]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([1,2,3,1,2,3]), np.array([0,0,0,0,0,0]),</span>
<span class="sd">        &gt;&gt;&gt;                                      np.array([[1,0,1], [1,0,2], [1,1,3], [2,0,1], ...]),</span>
<span class="sd">        &gt;&gt;&gt;                                      &#39;np.exp(((stim_x - x) ** 2) / (-2 * s ** 2))&#39;)</span>
<span class="sd">        array([0.35, 0.44, 0.24])</span>

<span class="sd">        Args:</span>
<span class="sd">            responses: Recorded activations</span>
<span class="sd">            stim_x: The stim_x variable contains an array with, for every row in the responses, what x variables were activated at that point.</span>
<span class="sd">            stim_y: The stim_y variable contains an array with, for every row in the responses, what y variables were activated at that point.</span>
<span class="sd">            candidate_function_parameters: A numpy array with, at each row, three variables for x, y, and sigma that will be evaluated by the function.</span>
<span class="sd">            prediction_function: The function that will generate the prediction. by default this is a simple gaussian function.</span>
<span class="sd">            stimulus_description (optional): The stimulus variable is an np.ndarray with, at each row, an array with the list of stimuli that were activated at that point.</span>
<span class="sd">            parallel (optional, default=True): Boolean indicating whether the algorithm should run parallel. Parallel processing makes the algorithm a lot faster.</span>
<span class="sd">            verbose (optional, default=False): Boolean indicating whether the function prints progress to the console.</span>
<span class="sd">            dtype (optional): The data type to store the data in when storing the data in a table</span>

<span class="sd">        Returns:</span>
<span class="sd">           np.ndarray containing the goodness of fits.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># If the stimulus is None, assume that each feature was shown once and one at the time represented by an identity matrix</span>
        <span class="k">if</span> <span class="n">stimulus_description</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">stimulus_description</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_x</span><span class="p">))</span>

        <span class="n">var_resp</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">o</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">parallel</span><span class="p">:</span>
            <span class="n">var_resp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">responses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">responses</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">responses_T</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">T</span>

        <span class="n">goodness_of_fits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">candidate_function_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">responses</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">candidate_function_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">disable</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">),</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">candidate_function_parameters</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
            <span class="n">evaluated_prediction_function</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">prediction_function</span><span class="p">)</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="p">(</span><span class="n">stimulus_description</span> <span class="o">@</span> <span class="n">evaluated_prediction_function</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">parallel</span><span class="p">:</span>
                <span class="n">_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">prediction</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">_x</span><span class="p">)</span> <span class="o">@</span> <span class="n">responses_T</span>
                <span class="n">variance_unexplained</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">responses_T</span> <span class="o">-</span> <span class="n">_x</span> <span class="o">@</span> <span class="n">scale</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">goodness_of_fit</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">variance_unexplained</span> <span class="o">/</span> <span class="n">var_resp</span><span class="p">)</span>  <span class="c1"># This is the inverted portion of the variance that is unexplained</span>
                <span class="n">goodness_of_fit</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">goodness_of_fit</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">goodness_of_fit</span><span class="p">[</span><span class="n">goodness_of_fit</span> <span class="o">==</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">goodness_of_fits</span><span class="p">[</span><span class="n">row</span><span class="p">]</span> <span class="o">=</span> <span class="n">goodness_of_fit</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">responses</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="n">goodness_of_fit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">prediction</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">responses</span><span class="p">[</span><span class="n">response</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
                    <span class="n">goodness_of_fits</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">response</span><span class="p">]</span> <span class="o">=</span> <span class="n">goodness_of_fit</span>
        <span class="k">return</span> <span class="n">goodness_of_fits</span>
</pre></div>

        </details>

            <div class="docstring"><p>Function that uses a prediction function to generate predictions for the activations of neurons for all the
candidate function parameters described in the <code>candidate_function_parameters</code> variable.</p>

<p>By default, the prediction_function is a gaussian function. Another example of a prediction functions could be 'stim_x**x'.
At the point of executing the prediction function stim_x, stim_y, x, y, and s are the available parameters.</p>

<p>The predictions are compared to the recorded responses to determine a goodness of fit.</p>

<h2 id="examples">Examples</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">FittingManager</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]]),</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]),</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="s1">&#39;np.exp(((stim_x - x) ** 2 + (stim_y - y) ** 2) / (-2 * s ** 2))&#39;</span><span class="p">)</span>
<span class="go">array([0.35, 0.44, 0.99])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">FittingManager</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]]),</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]),</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="o">...</span><span class="p">]),</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="s1">&#39;np.exp(((stim_x - x) ** 2) / (-2 * s ** 2))&#39;</span><span class="p">)</span>
<span class="go">array([0.35, 0.44, 0.24])</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>responses:</strong>  Recorded activations</li>
<li><strong>stim_x:</strong>  The stim_x variable contains an array with, for every row in the responses, what x variables were activated at that point.</li>
<li><strong>stim_y:</strong>  The stim_y variable contains an array with, for every row in the responses, what y variables were activated at that point.</li>
<li><strong>candidate_function_parameters:</strong>  A numpy array with, at each row, three variables for x, y, and sigma that will be evaluated by the function.</li>
<li><strong>prediction_function:</strong>  The function that will generate the prediction. by default this is a simple gaussian function.</li>
<li><strong>stimulus_description (optional):</strong>  The stimulus variable is an np.ndarray with, at each row, an array with the list of stimuli that were activated at that point.</li>
<li><strong>parallel (optional, default=True):</strong>  Boolean indicating whether the algorithm should run parallel. Parallel processing makes the algorithm a lot faster.</li>
<li><strong>verbose (optional, default=False):</strong>  Boolean indicating whether the function prints progress to the console.</li>
<li><strong>dtype (optional):</strong>  The data type to store the data in when storing the data in a table</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>np.ndarray containing the goodness of fits.</p>
</blockquote>
</div>


                            </div>
                            <div id="FittingManager.generate_fake_responses" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FittingManager.generate_fake_responses">#&nbsp;&nbsp</a>

                <div class="decorator">@staticmethod</div>

            <span class="def">def</span>
            <span class="name">generate_fake_responses</span><span class="signature">(variables, stim_x, stim_y, stimulus) -&gt; numpy.ndarray</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">generate_fake_responses</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates fake responses for the fitting test.</span>

<span class="sd">        Examples</span>
<span class="sd">        ------------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.generate_fake_responses([(1,1,2), (3,2,1)], (StimulusGenerator.stim_x, StimulusGenerator.stim_y), np.array([[0, 0, 1, 1, 0, 0], [1, 0, 1, 0, 0, 0]]))</span>
<span class="sd">        array([[1.48902756, 1.60653066],</span>
<span class="sd">               [0.44996444, 0.16417]])</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.generate_fake_responses([(2,3,1), (1,2,1)], (StimulusGenerator.stim_x, StimulusGenerator.stim_y), np.array([[0, 0, 1, 1, 0, 0], [1, 0, 1, 0, 0, 0]]))</span>
<span class="sd">        array([[0.74186594, 0.68861566],</span>
<span class="sd">               [0.9744101 , 1.21306132]])</span>

<span class="sd">        Args:</span>
<span class="sd">            variables: list of tuples containing the known variables</span>
<span class="sd">            stim_x: Stim x of the fake responses.</span>
<span class="sd">            stim_y: Stim y of the fake responses.</span>
<span class="sd">            stimulus: The stimulus of the fake responses.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray of fake responses.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nd_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">required_x</span><span class="p">,</span> <span class="n">required_y</span><span class="p">,</span> <span class="n">_required_s</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(((</span><span class="n">stim_x</span> <span class="o">-</span> <span class="n">required_x</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">stim_y</span> <span class="o">-</span> <span class="n">required_y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">_required_s</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">stimulus</span> <span class="o">@</span> <span class="n">g</span><span class="p">)</span>
            <span class="n">nd_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nd_list</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Generates fake responses for the fitting test.</p>

<h2 id="examples">Examples</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">FittingManager</span><span class="o">.</span><span class="n">generate_fake_responses</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)],</span> <span class="p">(</span><span class="n">StimulusGenerator</span><span class="o">.</span><span class="n">stim_x</span><span class="p">,</span> <span class="n">StimulusGenerator</span><span class="o">.</span><span class="n">stim_y</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="go">array([[1.48902756, 1.60653066],</span>
<span class="go">       [0.44996444, 0.16417]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">FittingManager</span><span class="o">.</span><span class="n">generate_fake_responses</span><span class="p">([(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)],</span> <span class="p">(</span><span class="n">StimulusGenerator</span><span class="o">.</span><span class="n">stim_x</span><span class="p">,</span> <span class="n">StimulusGenerator</span><span class="o">.</span><span class="n">stim_y</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="go">array([[0.74186594, 0.68861566],</span>
<span class="go">       [0.9744101 , 1.21306132]])</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>variables:</strong>  list of tuples containing the known variables</li>
<li><strong>stim_x:</strong>  Stim x of the fake responses.</li>
<li><strong>stim_y:</strong>  Stim y of the fake responses.</li>
<li><strong>stimulus:</strong>  The stimulus of the fake responses.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>np.ndarray of fake responses.</p>
</blockquote>
</div>


                            </div>
                            <div id="FittingManager.test_response_fitting" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FittingManager.test_response_fitting">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">test_response_fitting</span><span class="signature">(
    self,
    variables_to_discover,
    stimulus,
    stim_x,
    stim_y,
    candidate_function_parameters,
    parallel=False,
    verbose=False
)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">test_response_fitting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variables_to_discover</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span>
                              <span class="n">candidate_function_parameters</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tests the response fitting using known function parameters by generating fake responses, fitting parameters,</span>
<span class="sd">        and comparing the best fitted parameter with the known parameter.</span>

<span class="sd">        Args:</span>
<span class="sd">            variables_to_discover: list of tuples containing the known variables</span>
<span class="sd">            stimulus: The stimulus of the fake responses.</span>
<span class="sd">            stim_x: Stim x of the fake responses.</span>
<span class="sd">            stim_y: Stim y of the fake responses.</span>
<span class="sd">            candidate_function_parameters: The candidate parameters.</span>
<span class="sd">            parallel: Whether the function should use the parallel algorithm</span>
<span class="sd">            verbose: Whether the function should print progress to the command line.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray with the predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">generated_responses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_fake_responses</span><span class="p">(</span><span class="n">variables_to_discover</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">)</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_response_function</span><span class="p">(</span><span class="n">generated_responses</span><span class="p">,</span> <span class="n">stim_x</span><span class="p">,</span> <span class="n">stim_y</span><span class="p">,</span> <span class="n">candidate_function_parameters</span><span class="p">,</span>
                                               <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_best_fits</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">predicted</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
</pre></div>

        </details>

            <div class="docstring"><p>Tests the response fitting using known function parameters by generating fake responses, fitting parameters,
and comparing the best fitted parameter with the known parameter.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>variables_to_discover:</strong>  list of tuples containing the known variables</li>
<li><strong>stimulus:</strong>  The stimulus of the fake responses.</li>
<li><strong>stim_x:</strong>  Stim x of the fake responses.</li>
<li><strong>stim_y:</strong>  Stim y of the fake responses.</li>
<li><strong>candidate_function_parameters:</strong>  The candidate parameters.</li>
<li><strong>parallel:</strong>  Whether the function should use the parallel algorithm</li>
<li><strong>verbose:</strong>  Whether the function should print progress to the command line.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>np.ndarray with the predictions</p>
</blockquote>
</div>


                            </div>
                            <div id="FittingManager.linearise_sigma" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FittingManager.linearise_sigma">#&nbsp;&nbsp</a>

                <div class="decorator">@staticmethod</div>

            <span class="def">def</span>
            <span class="name">linearise_sigma</span><span class="signature">(log_sigma, x)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">linearise_sigma</span><span class="p">(</span><span class="n">log_sigma</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates a linear full width half maximum for a sigma variable.</span>

<span class="sd">        Examples</span>
<span class="sd">        -----------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.linearise_sigma(0.01, 3)</span>
<span class="sd">        0.07064623359911781</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.linearise_sigma(0.2, 5)</span>
<span class="sd">        2.3766436233783077</span>

<span class="sd">        Args:</span>
<span class="sd">            log_sigma: The sigma value in log space.</span>
<span class="sd">            x: The corresponding variable</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">fwhm_log</span> <span class="o">=</span> <span class="n">log_sigma</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
        <span class="n">fwhm_lin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_x</span> <span class="o">+</span> <span class="n">fwhm_log</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_x</span> <span class="o">-</span> <span class="n">fwhm_log</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fwhm_lin</span>
</pre></div>

        </details>

            <div class="docstring"><p>Calculates a linear full width half maximum for a sigma variable.</p>

<h2 id="examples">Examples</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">FittingManager</span><span class="o">.</span><span class="n">linearise_sigma</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">0.07064623359911781</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">FittingManager</span><span class="o">.</span><span class="n">linearise_sigma</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="go">2.3766436233783077</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>log_sigma:</strong>  The sigma value in log space.</li>
<li><strong>x:</strong>  The corresponding variable</li>
</ul>

<p>Returns:</p>
</div>


                            </div>
                            <div id="FittingManager.init_parameter_set" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FittingManager.init_parameter_set">#&nbsp;&nbsp</a>

                <div class="decorator">@staticmethod</div>

            <span class="def">def</span>
            <span class="name">init_parameter_set</span><span class="signature">(
    step: (&lt;class &#39;float&#39;&gt;, &lt;class &#39;float&#39;&gt;, &lt;class &#39;float&#39;&gt;),
    par_max: (&lt;class &#39;int&#39;&gt;, &lt;class &#39;int&#39;&gt;, &lt;class &#39;int&#39;&gt;),
    par_min: (&lt;class &#39;int&#39;&gt;, &lt;class &#39;int&#39;&gt;, &lt;class &#39;int&#39;&gt;),
    linearise_s: bool = False,
    log: bool = False
)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">init_parameter_set</span><span class="p">(</span><span class="n">step</span><span class="p">:</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">),</span> <span class="n">par_max</span><span class="p">:</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="n">par_min</span><span class="p">:</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span>
                           <span class="n">linearise_s</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                           <span class="n">log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialises the candidate function parameters by using the step and shape of the candidate parameters.</span>
<span class="sd">        Can linearise the sigma variable and move parameters into log space.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; FittingManager.init_parameter_set((1.,1.,0.1), (3.,3.,0.3), (1,1,0.1), False, False)</span>
<span class="sd">        array([[1. , 1. , 0.1],</span>
<span class="sd">               [1. , 1. , 0.2],</span>
<span class="sd">               [1. , 2. , 0.1],</span>
<span class="sd">               [1. , 2. , 0.2],</span>
<span class="sd">               [2. , 1. , 0.1],</span>
<span class="sd">               [2. , 1. , 0.2],</span>
<span class="sd">               [2. , 2. , 0.1],</span>
<span class="sd">               [2. , 2. , 0.2]], dtype=float32)</span>

<span class="sd">        Args:</span>
<span class="sd">            step: (float, float, float) The step sizes of the parameters.</span>
<span class="sd">            par_max: (int, int, int) The maximum of the parameters.</span>
<span class="sd">            par_min: (int, int, int) The minimum of the parameters.</span>
<span class="sd">            linearise_s: (bool) If true, the sigmas will get linearised.</span>
<span class="sd">            log: (bool) If true, the first two parameters are moved into log space.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray with at each row a set of parameter function parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">size</span> <span class="o">*</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">par_min</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">par_max</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">step</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
                    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                        <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">linearise_s</span><span class="p">:</span>
            <span class="n">p</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">FittingManager</span><span class="o">.</span><span class="n">linearise_sigma</span><span class="p">(</span><span class="n">p</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">p</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">p</span>
</pre></div>

        </details>

            <div class="docstring"><p>Initialises the candidate function parameters by using the step and shape of the candidate parameters.
Can linearise the sigma variable and move parameters into log space.</p>

<h2 id="examples">Examples</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">FittingManager</span><span class="o">.</span><span class="n">init_parameter_set</span><span class="p">((</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.1</span><span class="p">),</span> <span class="p">(</span><span class="mf">3.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">0.3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">),</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="go">array([[1. , 1. , 0.1],</span>
<span class="go">       [1. , 1. , 0.2],</span>
<span class="go">       [1. , 2. , 0.1],</span>
<span class="go">       [1. , 2. , 0.2],</span>
<span class="go">       [2. , 1. , 0.1],</span>
<span class="go">       [2. , 1. , 0.2],</span>
<span class="go">       [2. , 2. , 0.1],</span>
<span class="go">       [2. , 2. , 0.2]], dtype=float32)</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>step:</strong>  (float, float, float) The step sizes of the parameters.</li>
<li><strong>par_max:</strong>  (int, int, int) The maximum of the parameters.</li>
<li><strong>par_min:</strong>  (int, int, int) The minimum of the parameters.</li>
<li><strong>linearise_s:</strong>  (bool) If true, the sigmas will get linearised.</li>
<li><strong>log:</strong>  (bool) If true, the first two parameters are moved into log space.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>np.ndarray with at each row a set of parameter function parameters</p>
</blockquote>
</div>


                            </div>
                </section>
                <section id="StimulusGenerator">
                                <div class="attr class">
        <a class="headerlink" href="#StimulusGenerator">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">StimulusGenerator</span><wbr>(<span class="base">abc.ABC</span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">StimulusGenerator</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class for the StimulusGenerators.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates all input and saves the input to a table.</span>

<span class="sd">        Usage</span>
<span class="sd">        ------</span>
<span class="sd">        &gt;&gt;&gt; StimulusGenerator().generate((128,160))</span>

<span class="sd">        Args:</span>
<span class="sd">            shape: The expected shape of the input</span>

<span class="sd">        Returns:</span>
<span class="sd">            Table or TableSet containing the stimuli</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">stimulus_description</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates the stimulus description for use in the `FittingManager`</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray containing the stimulus variable to be used by the FittingManager.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">stim_x</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">stim_y</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
</pre></div>

        </details>

            <div class="docstring"><p>Abstract class for the StimulusGenerators.</p>
</div>


                            <div id="StimulusGenerator.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#StimulusGenerator.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">StimulusGenerator</span><span class="signature">()</span>
    </div>

        
    

                            </div>
                            <div id="StimulusGenerator.generate" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#StimulusGenerator.generate">#&nbsp;&nbsp</a>

                <div class="decorator">@abc.abstractmethod</div>

            <span class="def">def</span>
            <span class="name">generate</span><span class="signature">(
    self,
    shape: tuple
) -&gt; Union[<a href="nn_analysis/storage.html#Table">nn_analysis.storage.Table</a>, <a href="nn_analysis/storage.html#TableSet">nn_analysis.storage.TableSet</a>]</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates all input and saves the input to a table.</span>

<span class="sd">        Usage</span>
<span class="sd">        ------</span>
<span class="sd">        &gt;&gt;&gt; StimulusGenerator().generate((128,160))</span>

<span class="sd">        Args:</span>
<span class="sd">            shape: The expected shape of the input</span>

<span class="sd">        Returns:</span>
<span class="sd">            Table or TableSet containing the stimuli</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>

        </details>

            <div class="docstring"><p>Generates all input and saves the input to a table.</p>

<h2 id="usage">Usage</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">StimulusGenerator</span><span class="p">()</span><span class="o">.</span><span class="n">generate</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span><span class="mi">160</span><span class="p">))</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>shape:</strong>  The expected shape of the input</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>Table or TableSet containing the stimuli</p>
</blockquote>
</div>


                            </div>
                            <div id="StimulusGenerator.stimulus_description" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#StimulusGenerator.stimulus_description">#&nbsp;&nbsp</a>

        <span class="name">stimulus_description</span><span class="annotation">: numpy.ndarray</span>
    </div>

            <div class="docstring"><p>Generates the stimulus description for use in the <code><a href="#FittingManager">FittingManager</a></code></p>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>np.ndarray containing the stimulus variable to be used by the FittingManager.</p>
</blockquote>
</div>


                            </div>
                            <div id="StimulusGenerator.stim_x" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#StimulusGenerator.stim_x">#&nbsp;&nbsp</a>

        <span class="name">stim_x</span>
    </div>

    

                            </div>
                            <div id="StimulusGenerator.stim_y" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#StimulusGenerator.stim_y">#&nbsp;&nbsp</a>

        <span class="name">stim_y</span>
    </div>

    

                            </div>
                </section>
                <section id="InputManager">
                                <div class="attr class">
        <a class="headerlink" href="#InputManager">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">InputManager</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">InputManager</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class that manages the input and the batches.</span>
<span class="sd">    Takes an input generator as input. The generator saves the input to a table.</span>
<span class="sd">    That table is then used to determine which batches are valid and to retrieve input.</span>

<span class="sd">    Args:</span>
<span class="sd">        table: (`Table` or `TableSet`)  The table the input generator stores it&#39;s data to.</span>
<span class="sd">        shape: (tuple) A tuple of the shape of the input so it can be transformed to that.</span>
<span class="sd">        stimulus_generator: (`StimulusGenerator`) An StimulusGenerator that can generate input.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">],</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">stimulus_generator</span><span class="p">:</span> <span class="n">StimulusGenerator</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_table</span> <span class="o">=</span> <span class="n">table</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="k">if</span> <span class="n">stimulus_generator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">initialised</span><span class="p">):</span>
            <span class="n">stimulus_generator</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__prod</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The product of all iterable variables together</span>

<span class="sd">        Examples</span>
<span class="sd">        ----------</span>
<span class="sd">        &gt;&gt;&gt; __prod((1,2,3,4,5))</span>
<span class="sd">        120</span>
<span class="sd">        &gt;&gt;&gt; __prod((8, 12, 5))</span>
<span class="sd">        480</span>

<span class="sd">        Args:</span>
<span class="sd">            val: tuple</span>

<span class="sd">        Returns:</span>
<span class="sd">            The product as a float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="n">val</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">*=</span> <span class="n">ele</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">valid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determines if the batch is valid for the input table</span>

<span class="sd">        Examples</span>
<span class="sd">        ------------</span>
<span class="sd">        &gt;&gt;&gt; valid(1, 100)</span>
<span class="sd">        True</span>
<span class="sd">        &gt;&gt;&gt; valid(10, 100)</span>
<span class="sd">        False</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer of the batch that needs to be tested for validity</span>
<span class="sd">            batch_size: The size of the batches.</span>

<span class="sd">        Returns:</span>
<span class="sd">            boolean depicting the validity of the batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">nrows</span>

    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to get the input for a specific batch.</span>

<span class="sd">        Examples</span>
<span class="sd">        ----------</span>
<span class="sd">        &gt;&gt;&gt; get(0, 2)</span>
<span class="sd">        Array([</span>
<span class="sd">            [1,1,1,1,1,1,0,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...]</span>
<span class="sd">        ])</span>
<span class="sd">        &gt;&gt;&gt; get(0, 4)</span>
<span class="sd">        Array([</span>
<span class="sd">            [1,1,1,1,1,1,0,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...]</span>
<span class="sd">        ])</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer of the batch.</span>
<span class="sd">            batch_size: The size of the batch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray containing the input</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="n">batch_size</span>
        <span class="k">if</span> <span class="n">end</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">nrows</span><span class="p">:</span>
            <span class="n">end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">nrows</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Class that manages the input and the batches.
Takes an input generator as input. The generator saves the input to a table.
That table is then used to determine which batches are valid and to retrieve input.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>table:</strong>  (<code>Table</code> or <code>TableSet</code>)  The table the input generator stores it's data to.</li>
<li><strong>shape:</strong>  (tuple) A tuple of the shape of the input so it can be transformed to that.</li>
<li><strong>stimulus_generator:</strong>  (<code><a href="#StimulusGenerator">StimulusGenerator</a></code>) An StimulusGenerator that can generate input.</li>
</ul>
</div>


                            <div id="InputManager.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#InputManager.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">InputManager</span><span class="signature">(
    table: Union[<a href="nn_analysis/storage.html#Table">nn_analysis.storage.Table</a>, <a href="nn_analysis/storage.html#TableSet">nn_analysis.storage.TableSet</a>],
    shape: tuple,
    stimulus_generator: <a href="#StimulusGenerator">nn_analysis.StimulusGenerator</a> = None
)</span>
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Table</span><span class="p">,</span> <span class="n">TableSet</span><span class="p">],</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">stimulus_generator</span><span class="p">:</span> <span class="n">StimulusGenerator</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_table</span> <span class="o">=</span> <span class="n">table</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="k">if</span> <span class="n">stimulus_generator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">initialised</span><span class="p">):</span>
            <span class="n">stimulus_generator</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

        </details>

    

                            </div>
                            <div id="InputManager.valid" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#InputManager.valid">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">valid</span><span class="signature">(self, batch: int, batch_size: int) -&gt; bool</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">valid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determines if the batch is valid for the input table</span>

<span class="sd">        Examples</span>
<span class="sd">        ------------</span>
<span class="sd">        &gt;&gt;&gt; valid(1, 100)</span>
<span class="sd">        True</span>
<span class="sd">        &gt;&gt;&gt; valid(10, 100)</span>
<span class="sd">        False</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer of the batch that needs to be tested for validity</span>
<span class="sd">            batch_size: The size of the batches.</span>

<span class="sd">        Returns:</span>
<span class="sd">            boolean depicting the validity of the batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">nrows</span>
</pre></div>

        </details>

            <div class="docstring"><p>Determines if the batch is valid for the input table</p>

<h2 id="examples">Examples</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">valid</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">valid</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="go">False</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>batch:</strong>  Integer of the batch that needs to be tested for validity</li>
<li><strong>batch_size:</strong>  The size of the batches.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>boolean depicting the validity of the batch.</p>
</blockquote>
</div>


                            </div>
                            <div id="InputManager.get" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#InputManager.get">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">get</span><span class="signature">(self, batch: int, batch_size: int) -&gt; numpy.ndarray</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to get the input for a specific batch.</span>

<span class="sd">        Examples</span>
<span class="sd">        ----------</span>
<span class="sd">        &gt;&gt;&gt; get(0, 2)</span>
<span class="sd">        Array([</span>
<span class="sd">            [1,1,1,1,1,1,0,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...]</span>
<span class="sd">        ])</span>
<span class="sd">        &gt;&gt;&gt; get(0, 4)</span>
<span class="sd">        Array([</span>
<span class="sd">            [1,1,1,1,1,1,0,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...],</span>
<span class="sd">            [0,1,1,1,1,1,1,0,0,0,0,0,0,...]</span>
<span class="sd">        ])</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: Integer of the batch.</span>
<span class="sd">            batch_size: The size of the batch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray containing the input</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="n">batch_size</span>
        <span class="k">if</span> <span class="n">end</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">nrows</span><span class="p">:</span>
            <span class="n">end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="o">.</span><span class="n">nrows</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_table</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Function to get the input for a specific batch.</p>

<h2 id="examples">Examples</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">get</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">Array([</span>
<span class="go">    [1,1,1,1,1,1,0,0,0,0,0,0,0,...],</span>
<span class="go">    [0,1,1,1,1,1,1,0,0,0,0,0,0,...]</span>
<span class="go">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">get</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="go">Array([</span>
<span class="go">    [1,1,1,1,1,1,0,0,0,0,0,0,0,...],</span>
<span class="go">    [0,1,1,1,1,1,1,0,0,0,0,0,0,...],</span>
<span class="go">    [0,1,1,1,1,1,1,0,0,0,0,0,0,...],</span>
<span class="go">    [0,1,1,1,1,1,1,0,0,0,0,0,0,...]</span>
<span class="go">])</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>batch:</strong>  Integer of the batch.</li>
<li><strong>batch_size:</strong>  The size of the batch.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>np.ndarray containing the input</p>
</blockquote>
</div>


                            </div>
                </section>
                <section id="OutputManager">
                                <div class="attr class">
        <a class="headerlink" href="#OutputManager">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">OutputManager</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">OutputManager</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The `OutputManager` is the class that goes through batches of input.</span>
<span class="sd">    The batches are retrieved from the provided `InputManager`.</span>
<span class="sd">    The results are stored using the provided `StorageManager`.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        network: The `Network` that will be used.</span>
<span class="sd">        storage_manager: The `StorageManager` that will allow for saving the results.</span>
<span class="sd">        input_manager: The `InputManager` that will provide the input</span>

<span class="sd">    Args:</span>
<span class="sd">        network: The `Network` that will be used.</span>
<span class="sd">        storage_manager: The `StorageManager` that will allow for saving the results.</span>
<span class="sd">        input_manager: The `InputManager` that will provide the input</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">Network</span><span class="p">,</span> <span class="n">storage_manager</span><span class="p">:</span> <span class="n">StorageManager</span><span class="p">,</span> <span class="n">input_manager</span><span class="p">:</span> <span class="n">InputManager</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span> <span class="o">=</span> <span class="n">storage_manager</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_manager</span> <span class="o">=</span> <span class="n">input_manager</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">resume</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function runs a batch through a `Network`</span>

<span class="sd">        Examples</span>
<span class="sd">        -----------</span>
<span class="sd">        &gt;&gt;&gt; run(&#39;TableName&#39;, 100)</span>
<span class="sd">        &gt;&gt;&gt; run(&#39;TableName&#39;, 100, resume=True, verbose=True)</span>

<span class="sd">        Args:</span>
<span class="sd">            table: `Table` to save data to</span>
<span class="sd">            batch_size: (int) Size of the batches to input into the network</span>
<span class="sd">            override (optional, default=True): (bool) determines whether the table gets extended or overridden (default=False)</span>
<span class="sd">            resume (optional, default=False): (bool) resume at last batch on failure</span>
<span class="sd">            verbose (optional, default=False): (bool) outputs the current batch and total percentage done</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">override</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">resume</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">remove_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">resume</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">tbl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">open_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tbl</span><span class="o">.</span><span class="n">initialised</span><span class="p">:</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">tbl</span><span class="o">.</span><span class="n">nrows</span><span class="o">/</span><span class="n">batch_size</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">except</span> <span class="n">NoSuchTableError</span><span class="p">:</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">batch_end</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_manager</span><span class="o">.</span><span class="n">valid</span><span class="p">(</span><span class="n">batch_end</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">batch_end</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_end</span><span class="p">),</span> <span class="n">disable</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">current_batch</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">network_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_manager</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="n">network_output</span><span class="p">,</span> <span class="n">network_output_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">network_input</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">(</span><span class="n">network_output</span><span class="p">,</span> <span class="n">table</span><span class="p">,</span> <span class="n">network_output_labels</span><span class="p">,</span> <span class="n">append_rows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">batch</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

        </details>

            <div class="docstring"><p>The <code><a href="#OutputManager">OutputManager</a></code> is the class that goes through batches of input.
The batches are retrieved from the provided <code><a href="#InputManager">InputManager</a></code>.
The results are stored using the provided <code>StorageManager</code>.</p>

<h6 id="attributes">Attributes</h6>

<ul>
<li><strong>network:</strong>  The <code><a href="#Network">Network</a></code> that will be used.</li>
<li><strong>storage_manager:</strong>  The <code>StorageManager</code> that will allow for saving the results.</li>
<li><strong>input_manager:</strong>  The <code><a href="#InputManager">InputManager</a></code> that will provide the input</li>
</ul>

<h6 id="args">Args</h6>

<ul>
<li><strong>network:</strong>  The <code><a href="#Network">Network</a></code> that will be used.</li>
<li><strong>storage_manager:</strong>  The <code>StorageManager</code> that will allow for saving the results.</li>
<li><strong>input_manager:</strong>  The <code><a href="#InputManager">InputManager</a></code> that will provide the input</li>
</ul>
</div>


                            <div id="OutputManager.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#OutputManager.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">OutputManager</span><span class="signature">(
    network: <a href="#Network">nn_analysis.Network</a>,
    storage_manager: <a href="nn_analysis/storage.html#StorageManager">nn_analysis.storage.StorageManager</a>,
    input_manager: <a href="#InputManager">nn_analysis.InputManager</a>
)</span>
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">Network</span><span class="p">,</span> <span class="n">storage_manager</span><span class="p">:</span> <span class="n">StorageManager</span><span class="p">,</span> <span class="n">input_manager</span><span class="p">:</span> <span class="n">InputManager</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span> <span class="o">=</span> <span class="n">storage_manager</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_manager</span> <span class="o">=</span> <span class="n">input_manager</span>
</pre></div>

        </details>

    

                            </div>
                            <div id="OutputManager.run" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#OutputManager.run">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">run</span><span class="signature">(
    self,
    table: str,
    batch_size: int,
    override: bool = True,
    resume: bool = False,
    verbose: bool = False
)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">resume</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function runs a batch through a `Network`</span>

<span class="sd">        Examples</span>
<span class="sd">        -----------</span>
<span class="sd">        &gt;&gt;&gt; run(&#39;TableName&#39;, 100)</span>
<span class="sd">        &gt;&gt;&gt; run(&#39;TableName&#39;, 100, resume=True, verbose=True)</span>

<span class="sd">        Args:</span>
<span class="sd">            table: `Table` to save data to</span>
<span class="sd">            batch_size: (int) Size of the batches to input into the network</span>
<span class="sd">            override (optional, default=True): (bool) determines whether the table gets extended or overridden (default=False)</span>
<span class="sd">            resume (optional, default=False): (bool) resume at last batch on failure</span>
<span class="sd">            verbose (optional, default=False): (bool) outputs the current batch and total percentage done</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">override</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">resume</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">remove_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">resume</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">tbl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">open_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tbl</span><span class="o">.</span><span class="n">initialised</span><span class="p">:</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">tbl</span><span class="o">.</span><span class="n">nrows</span><span class="o">/</span><span class="n">batch_size</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">except</span> <span class="n">NoSuchTableError</span><span class="p">:</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">batch_end</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_manager</span><span class="o">.</span><span class="n">valid</span><span class="p">(</span><span class="n">batch_end</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">batch_end</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_end</span><span class="p">),</span> <span class="n">disable</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">current_batch</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">network_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_manager</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="n">network_output</span><span class="p">,</span> <span class="n">network_output_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">network_input</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage_manager</span><span class="o">.</span><span class="n">save_result_table_set</span><span class="p">(</span><span class="n">network_output</span><span class="p">,</span> <span class="n">table</span><span class="p">,</span> <span class="n">network_output_labels</span><span class="p">,</span> <span class="n">append_rows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">batch</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

        </details>

            <div class="docstring"><p>Function runs a batch through a <code><a href="#Network">Network</a></code></p>

<h2 id="examples">Examples</h2>

<div class="codehilite"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;TableName&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;TableName&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">resume</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<h6 id="args">Args</h6>

<ul>
<li><strong>table:</strong>  <code>Table</code> to save data to</li>
<li><strong>batch_size:</strong>  (int) Size of the batches to input into the network</li>
<li><strong>override (optional, default=True):</strong>  (bool) determines whether the table gets extended or overridden (default=False)</li>
<li><strong>resume (optional, default=False):</strong>  (bool) resume at last batch on failure</li>
<li><strong>verbose (optional, default=False):</strong>  (bool) outputs the current batch and total percentage done</li>
</ul>
</div>


                            </div>
                </section>
                <section id="Plot">
                                <div class="attr class">
        <a class="headerlink" href="#Plot">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">Plot</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Plot</span><span class="p">:</span>

    <span class="n">save_fig</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">save_fig_folder</span> <span class="o">=</span> <span class="s1">&#39;./&#39;</span>
    <span class="n">filetype</span> <span class="o">=</span> <span class="s1">&#39;png&#39;</span>
    <span class="n">title</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="n">plot</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">no_plotting</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;This function requires matplotlib. Please install matplotlib and try again.&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Plot</span><span class="o">.</span><span class="n">save_fig</span><span class="p">:</span>
            <span class="n">tmp_title</span> <span class="o">=</span> <span class="n">Plot</span><span class="o">.</span><span class="n">title</span> <span class="k">if</span> <span class="n">Plot</span><span class="o">.</span><span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">microsecond</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">Plot</span><span class="o">.</span><span class="n">save_fig_folder</span><span class="si">}{</span><span class="n">tmp_title</span><span class="si">}</span><span class="s1">.</span><span class="si">{</span><span class="n">Plot</span><span class="o">.</span><span class="n">filetype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="n">plot</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">plot</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
        <span class="n">Plot</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
</pre></div>

        </details>

    

                            <div id="Plot.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Plot.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">Plot</span><span class="signature">()</span>
    </div>

        
    

                            </div>
                            <div id="Plot.save_fig" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#Plot.save_fig">#&nbsp;&nbsp</a>

        <span class="name">save_fig</span><span class="default_value"> = False</span>
    </div>

    

                            </div>
                            <div id="Plot.save_fig_folder" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#Plot.save_fig_folder">#&nbsp;&nbsp</a>

        <span class="name">save_fig_folder</span><span class="default_value"> = &#39;./&#39;</span>
    </div>

    

                            </div>
                            <div id="Plot.filetype" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#Plot.filetype">#&nbsp;&nbsp</a>

        <span class="name">filetype</span><span class="default_value"> = &#39;png&#39;</span>
    </div>

    

                            </div>
                            <div id="Plot.title" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#Plot.title">#&nbsp;&nbsp</a>

        <span class="name">title</span><span class="default_value"> = None</span>
    </div>

    

                            </div>
                            <div id="Plot.show" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Plot.show">#&nbsp;&nbsp</a>

                <div class="decorator">@staticmethod</div>

            <span class="def">def</span>
            <span class="name">show</span><span class="signature">(plot)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="n">plot</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">no_plotting</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;This function requires matplotlib. Please install matplotlib and try again.&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Plot</span><span class="o">.</span><span class="n">save_fig</span><span class="p">:</span>
            <span class="n">tmp_title</span> <span class="o">=</span> <span class="n">Plot</span><span class="o">.</span><span class="n">title</span> <span class="k">if</span> <span class="n">Plot</span><span class="o">.</span><span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">microsecond</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">Plot</span><span class="o">.</span><span class="n">save_fig_folder</span><span class="si">}{</span><span class="n">tmp_title</span><span class="si">}</span><span class="s1">.</span><span class="si">{</span><span class="n">Plot</span><span class="o">.</span><span class="n">filetype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="n">plot</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">plot</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
        <span class="n">Plot</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
</pre></div>

        </details>

    

                            </div>
                </section>
                <section id="tf">
                            <div class="attr function"><a class="headerlink" href="#tf">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">tf</span><span class="signature">()</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="n">tf</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="kc">None</span>
</pre></div>

        </details>

    

                </section>
    </main>
</body>
</html>